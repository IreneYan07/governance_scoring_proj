{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12278ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error occurred during getting browser(s): random, but was suppressed with fallback.\n"
     ]
    }
   ],
   "source": [
    "# import libraries and set parameters \n",
    "\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import zipfile \n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "from concurrent.futures import ThreadPoolExecutor \n",
    "\n",
    "import dart_fss\n",
    "import OpenDartReader\n",
    "from datetime import datetime\n",
    "\n",
    "API_key = '0d67945133e224c451452e071e0d8349969353e1' \n",
    "dart = OpenDartReader(API_key)\n",
    "dart_fss.set_api_key(API_key)\n",
    "\n",
    "current_year = 2025\n",
    "bsns_year = '2024' # from most recent annual report\n",
    "reprt_code = '11011'\n",
    "asset_year = '2024' # set to a year before bsns year due to grace period for corps surpassing 2 trillion krw \n",
    "current_date = '2025.08.07'\n",
    "\n",
    "# call most recent annual/semi-annual report as quarterly may exclude audit info due to corporate disclosure form preparation standards "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88257088",
   "metadata": {},
   "source": [
    "Take in Raw Data. Clean, standardize, and parse. Produce an individual_df and standardized_summary_df \n",
    "\n",
    "individual_df \n",
    "- assign salary\n",
    "- check that salary numbers add up \n",
    "\n",
    "group_df \n",
    "- counts of all \n",
    "- governance check/flag \n",
    "\n",
    "# TODO: fully fix exec-df \n",
    "- standardize tenure \n",
    "- group data \n",
    "- make sure that audit commmittee membership is correct (governance check -> if same problems come up, extract audit committee membership from financial doc)\n",
    "- standardize education \n",
    "\n",
    "# TODO: group data \n",
    "- sumarize the exec_df + get the counts \n",
    "- check that the total comp of summary_df = the salary_total comp vals \n",
    "- standardize tenure \n",
    "\n",
    "# At Large: \n",
    "- check that audit committee members are correct \n",
    "\n",
    "# 08/08 TODO:\n",
    "- fix auditor placeholder logic + flagging \n",
    "- fix exec updating \n",
    "- parse prof_background to separate edu / work experience\n",
    "- rename columns \n",
    "- save all processed df's \n",
    "- clean notebooks \n",
    "\n",
    "\n",
    "# Documentation Format: \n",
    "- the produced data frames\n",
    "- the full code and explaining decision processes (ie why est/exact for salary, the flags for audit committee, assets check from 2 years ago), what columns were droppped, etc \n",
    "\n",
    "# Useful OpenDART links: \n",
    "- https://opendart.fss.or.kr/guide/detail.do?apiGrpCd=DE004&apiId=AE00041 Ownership change (most recent data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "039baf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Read in Files: if run before, read in the files \n",
    "all_corp_codes_df = pd.read_csv(r'C:\\Program Files\\Git\\OPENDART\\governance_scoring_proj\\notebooks\\data\\raw\\listed_corp_codes.csv')\n",
    "kospi_company_info_df = pd.read_csv(r'C:\\Program Files\\Git\\OPENDART\\governance_scoring_proj\\notebooks\\data\\raw\\kospi_company_info.csv')\n",
    "executive_status_data_df = pd.read_csv(r'C:\\Program Files\\Git\\OPENDART\\governance_scoring_proj\\notebooks\\data\\raw\\executive_status_2024_11011.csv')\n",
    "assets_df = pd.read_csv(r'C:\\Program Files\\Git\\OPENDART\\governance_scoring_proj\\notebooks\\data\\raw\\assets_2024_11011.csv')\n",
    "salary_type_df = pd.read_csv(r'C:\\Program Files\\Git\\OPENDART\\governance_scoring_proj\\notebooks\\data\\raw\\salary_data_2024_11011.csv')\n",
    "salary_total_df = pd.read_csv(r'C:\\Program Files\\Git\\OPENDART\\governance_scoring_proj\\notebooks\\data\\raw\\salary_total_data_2024_11011.csv')\n",
    "major_shareholder_df = pd.read_csv(r'C:\\Program Files\\Git\\OPENDART\\governance_scoring_proj\\notebooks\\data\\raw\\major_shareholders_2024_11011.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a12fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_df = executive_status_data_df.drop(columns=['corp_cls', 'birth_ym', 'fte_at', 'tenure_end_on', 'stlm_dt'], errors='ignore')\n",
    "\n",
    "def is_audit_committee_member(responsibility, position):\n",
    "\n",
    "    responsibility_cleaned = re.sub(r'\\s', '', responsibility)\n",
    "    \n",
    "    return bool(re.search(r'감사위원회위원|감사위원|감사위원장', responsibility_cleaned)) \n",
    "\n",
    "def is_auditor_exclusive(responsibility, position): #isolated capture to not overlap with is_audit_committee_member\n",
    "    if is_audit_committee_member(responsibility, position):\n",
    "        return False\n",
    "    \n",
    "    responsibility_check = False\n",
    "    if isinstance(responsibility, str):\n",
    "        responsibility_cleaned = re.sub(r'\\s', '', responsibility)\n",
    "\n",
    "        responsibility_check = '감사' in responsibility_cleaned and not re.search(r'감사위원회위원|감사위원', responsibility_cleaned) \n",
    "    position_check = False \n",
    "\n",
    "\n",
    "    return responsibility_check or position_check\n",
    "\n",
    "# apply updated audit membership \n",
    "exec_df['is_audit_committee_member'] = exec_df.apply(\n",
    "    lambda row: is_audit_committee_member(row['chrg_job'], row['rgist_exctv_at']), axis=1\n",
    ")\n",
    "\n",
    "exec_df['is_auditor'] = exec_df.apply(\n",
    "    lambda row: is_auditor_exclusive(row['chrg_job'], row['rgist_exctv_at']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "778c93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_compensation(exec_df: pd.DataFrame, salary_type_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assign salary from compensation_df to each executive in exec_df.\n",
    "    Uses individual match first; falls back on average grouped position compensation if registered.\n",
    "    Leaves '미등기' status executives empty unless exact match is found.\n",
    "    \"\"\"\n",
    "    exec_df['salary'] = None\n",
    "    exec_df['salary_source'] = None\n",
    "    exec_df['salary_type'] = None\n",
    "\n",
    "    for idx, row in exec_df.iterrows():\n",
    "        corp_code = row['corp_code']\n",
    "        name = row['nm']\n",
    "        status = row.get('rgist_exctv_at')\n",
    "        is_auditor = row.get('is_auditor', False)\n",
    "        is_committee = row.get('is_audit_committee_member', False)\n",
    "\n",
    "        # 1. Try to match by name\n",
    "        match = salary_type_df[\n",
    "            (salary_type_df['corp_code'] == corp_code) & \n",
    "            (salary_type_df['name'] == name)\n",
    "        ]\n",
    "\n",
    "        if not match.empty:\n",
    "            row_data = match.iloc[0]\n",
    "\n",
    "        else:\n",
    "            if status == '미등기':\n",
    "                label = '미등기임원' \n",
    "            # 2. Estimate fallback: build label\n",
    "            elif is_auditor:\n",
    "                label = '감사'\n",
    "            elif status == '사외이사':\n",
    "                label = '감사위원회 위원' if is_committee else '사외이사(감사위원회 위원 제외)'\n",
    "            else:\n",
    "                label = '등기이사(사외이사, 감사위원회 위원 제외)'\n",
    "\n",
    "            group_match = salary_type_df[\n",
    "                (salary_type_df['corp_code'] == corp_code) & \n",
    "                (salary_type_df['name'].isna()) & \n",
    "                (salary_type_df['position'] == label)\n",
    "            ]\n",
    "\n",
    "            row_data = group_match.iloc[0] if not group_match.empty else pd.Series(dtype='object')\n",
    "\n",
    "        # 3. Assign if valid\n",
    "        if not row_data.empty:\n",
    "            exec_df.at[idx, 'salary'] = row_data.get('compensation')\n",
    "            exec_df.at[idx, 'salary_source'] = row_data.get('salary_source')\n",
    "            exec_df.at[idx, 'salary_type'] = row_data.get('salary_type')\n",
    "\n",
    "    return exec_df\n",
    "\n",
    "exec_df = assign_compensation(exec_df, salary_type_df)\n",
    "\n",
    "exec_df = pd.merge(\n",
    "    exec_df, \n",
    "    major_shareholder_df[['corp_code', 'nm', 'trmend_posesn_stock_qota_rt']],\n",
    "    on=['corp_code', 'nm'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc2e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tenure_to_months(tenure_str, current_date=None):\n",
    "    \"\"\"\n",
    "    Converts a tenure string from various formats into a total number of months.\n",
    "    \n",
    "    Args:\n",
    "        tenure_str (str): The string representing tenure (e.g., '2년 6개월', '2022.05', '11.3년').\n",
    "        current_date (datetime): The reference date to calculate tenure from a start date.\n",
    "                                 Defaults to today's date if not provided.\n",
    "\n",
    "    Returns:\n",
    "        float: The total tenure in months, or pd.NA if the format is not recognized.\n",
    "    \"\"\"\n",
    "    if pd.isna(tenure_str) or not isinstance(tenure_str, str) or not tenure_str.strip():\n",
    "        return pd.NA\n",
    "        \n",
    "    tenure_str = tenure_str.strip()\n",
    "    \n",
    "    # 1. Pattern: All date formats, including those with extra text\n",
    "    date_match = re.search(r'(\\d{2,4}[년\\.\\s]\\d{1,2}[월]?(?:[년\\.\\s]\\d{1,2}[일])?|\\d{1,2}\\.\\d{1,2}\\.\\d{1,2})', tenure_str)\n",
    "    \n",
    "    if date_match:\n",
    "        date_str = date_match.group(1).replace(' ', '').replace('년', '.').replace('월', '').replace('일', '')\n",
    "        date_obj = pd.NaT\n",
    "        \n",
    "        # Now try to parse the cleaned date string with multiple formats\n",
    "        date_formats = ['%Y.%m.%d', '%Y.%m', '%d.%m.%y', '%y.%m.%d', '%y.%m']\n",
    "        for fmt in date_formats:\n",
    "            try:\n",
    "                date_obj = pd.to_datetime(date_str, format=fmt, errors='raise')\n",
    "                break # Exit the loop if parsing is successful\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "    \n",
    "        if pd.notna(date_obj):\n",
    "            if current_date is None:\n",
    "                current_date = datetime.now()\n",
    "            \n",
    "            total_months = (current_date.year - date_obj.year) * 12 + (current_date.month - date_obj.month)\n",
    "            return float(max(0, total_months))\n",
    "    \n",
    "    # 2. Pattern: Decimal years (e.g., '11.3년', '22.5')\n",
    "    match_deci = re.search(r'^(\\d+(?:\\.\\d+)?)(?:년)?$', tenure_str)\n",
    "    if match_deci:\n",
    "        decimal_years = float(match_deci.group(1))\n",
    "        return decimal_years * 12\n",
    "    \n",
    "    # 3. Pattern: Years and Months (e.g., \"3년 6개월\", \"4년4개월\")\n",
    "    match_ym = re.search(r'(\\d+)\\s*년(?:[^\\d]+)?\\s*(\\d+)\\s*개월', tenure_str)\n",
    "    if match_ym:\n",
    "        years = int(match_ym.group(1))\n",
    "        months = int(match_ym.group(2))\n",
    "        return float(years * 12 + months)\n",
    "        \n",
    "    # 4. Pattern: Only Years (e.g., \"3년\")\n",
    "    match_y = re.search(r'^(\\d+)\\s*년$', tenure_str)\n",
    "    if match_y:\n",
    "        years = int(match_y.group(1))\n",
    "        return float(years * 12)\n",
    "        \n",
    "    # 5. Pattern: Only Months (e.g., \"18개월\")\n",
    "    match_m = re.search(r'^(\\d+)\\s*개월$', tenure_str)\n",
    "    if match_m:\n",
    "        months = int(match_m.group(1))\n",
    "        return float(months)\n",
    "    \n",
    "    return pd.NA\n",
    "\n",
    "# Set a specific reference date for consistent tenure calculation\n",
    "reference_date = datetime(2025, 8, 5)\n",
    "\n",
    "# Apply the custom function to the column\n",
    "exec_df['hffc_pd'] = exec_df['hffc_pd'].apply(\n",
    "    lambda x: convert_tenure_to_months(x, current_date=reference_date)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55bcbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_2320\\1769259283.py:29: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  summary_df = exec_df.groupby(['corp_code', 'corp_name']).apply(extract_summary).reset_index()\n"
     ]
    }
   ],
   "source": [
    "def extract_summary(group):\n",
    "    voting_directors_group = group[~group['rgist_exctv_at'].isin(['미등기', '감사'])]\n",
    "\n",
    "    female_voting = (voting_directors_group['sexdstn'] == '여').sum()\n",
    "    male_voting = (voting_directors_group['sexdstn'] == '남').sum()\n",
    "    \n",
    "    return pd.Series({\n",
    "        \n",
    "        # total counts for all individuals \n",
    "        'Audit Committee': group['is_audit_committee_member'].sum(),\n",
    "        'Audit Committee ODs': ((group['is_audit_committee_member'] == True) & (group['rgist_exctv_at'] == '사외이사')).sum(),\n",
    "        'Inside Directors': group['rgist_exctv_at'].isin(['사내이사', '대표집행임원']).sum(),\n",
    "        'Outside Directors': (group['rgist_exctv_at'] == '사외이사').sum(),\n",
    "        'Other Non-Exec Directors': (group['rgist_exctv_at'] == '기타비상무이사').sum(),\n",
    "        'Auditors': group['is_auditor'].sum(),\n",
    "        \n",
    "        # counts for Voting Directors subset\n",
    "        'Female Voting': female_voting,\n",
    "        'Male Voting': male_voting,\n",
    "        'Voting Directors': female_voting + male_voting,\n",
    "\n",
    "        # count for Non-Registered (separate)\n",
    "        'Non Registered': (group['rgist_exctv_at'] == '미등기').sum()\n",
    "    })\n",
    "\n",
    "\n",
    "# merge with kospi_codes to append corp_code, required for financial statment search in next section \n",
    "# Item code and stock_code are interchangeable \n",
    "summary_df = exec_df.groupby(['corp_code', 'corp_name']).apply(extract_summary).reset_index()\n",
    "summary_df = pd.merge(summary_df, assets_df[['Corp Code', 'Total Assets (2024)', 'Total Assets (2023)', 'Total Assets (2022)']], left_on='corp_code', right_on='Corp Code', how='left')\n",
    "summary_df.drop(columns=['Corp Code'], inplace=True)\n",
    "\n",
    "rcept_no = exec_df.groupby('corp_code')['rcept_no'].max().reset_index()\n",
    "rcept_no.rename(columns={'rcept_no': 'rcept_no'}, inplace=True)\n",
    "summary_df = pd.merge(summary_df, rcept_no, on='corp_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b2f84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_governance_compliance(df):\n",
    "    \"\"\"\n",
    "    Evaluates governance compliance based on board and audit committee rules.\n",
    "    Returns:\n",
    "        pd.DataFrame with flagged issues for non-compliant companies.\n",
    "    \"\"\"\n",
    "    flagged = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        corp_code = row['corp_code']\n",
    "        total_assets = row['Total Assets (2022)']\n",
    "        num_audit_committee = row['Audit Committee']\n",
    "        num_outside_directors = row['Outside Directors']\n",
    "        num_voting_directors = row['Voting Directors']\n",
    "        num_outside_committee = row['Audit Committee ODs']\n",
    "\n",
    "        failures = []\n",
    "\n",
    "        # Check audit committee compliances\n",
    "        if pd.notna(total_assets) and total_assets > 2_000_000_000_000:\n",
    "            if pd.isna(num_audit_committee) or num_audit_committee == 0:\n",
    "                failures.append(\"No Audit Committee listed\")\n",
    "            elif num_audit_committee < 3:\n",
    "                failures.append(f\"Audit Committee has fewer than 3 members ({num_audit_committee})\")\n",
    "\n",
    "            if pd.notna(num_audit_committee) and num_audit_committee > 0:\n",
    "                if pd.isna(num_outside_committee):\n",
    "                    failures.append(\"Missing count of Audit Committee Outside Directors.\")\n",
    "                elif num_outside_committee < (2/3) * num_audit_committee:\n",
    "                    failures.append(f\"Audit Committee Outside Directors ({num_outside_committee}) < 2/3 of Audit Committee ({num_audit_committee})\")\n",
    "            if num_outside_directors < (1/4) * num_voting_directors:\n",
    "                failures.append(f\"Outside Directors ({num_outside_directors}) < 1/4 of Voting Directors ({num_voting_directors})\")\n",
    "\n",
    "        if failures:\n",
    "            flagged.append({'corp_code': corp_code, 'Flagged Conditions': \"; \".join(failures)})\n",
    "\n",
    "    failed_df = pd.DataFrame(flagged)\n",
    "    failed_df['corp_code'] = failed_df['corp_code']\n",
    "\n",
    "    # Merge with original data\n",
    "    return pd.merge(failed_df, df, on='corp_code', how='inner')\n",
    "\n",
    "flagged = check_governance_compliance(summary_df) \n",
    "\n",
    "# ~ 75 flagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436f6f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch for 101220 (20250320001653): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Failed to fetch for 102432 (20250318001013): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Failed to fetch for 104856 (20250306000628): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Failed to fetch for 106669 (20250318000465): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Failed to fetch for 108135 (20250318001422): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Failed to fetch for 108241 (20250312000711): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Failed to fetch for 111810 (20250401003907): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Failed to fetch for 113058 (20250331003702): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Failed to fetch for 113191 (20250331003380): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(results)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# 3. Retrieve target audit committee document URLs for flagged cases\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m audit_targets_df = \u001b[43mmissing_acm_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflagged\u001b[49m\u001b[43m)\u001b[49m.drop_duplicates(subset=[\u001b[33m'\u001b[39m\u001b[33mcorp_code\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mmissing_acm_urls\u001b[39m\u001b[34m(flagged_df)\u001b[39m\n\u001b[32m     21\u001b[39m         url = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     23\u001b[39m     results.append({\n\u001b[32m     24\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcorp_code\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(corp),\n\u001b[32m     25\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcorp_name\u001b[39m\u001b[33m'\u001b[39m: company,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mTotal Assets (2022)\u001b[39m\u001b[33m'\u001b[39m: assets\n\u001b[32m     29\u001b[39m     })\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(results)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def missing_acm_urls(flagged_df):\n",
    "    results = []\n",
    "\n",
    "    for idx, row in flagged_df.iterrows():\n",
    "        company = row['corp_name']\n",
    "        corp = row['corp_code']\n",
    "        rcp = row['rcept_no'] # update to append the disclosure from exec_df most recent \n",
    "        assets = row['Total Assets (2022)']\n",
    "\n",
    "        try:\n",
    "            subdocs = dart.sub_docs(str(rcp))  # rcept_no must be string\n",
    "            match = subdocs[subdocs['title'].str.contains(\"감사제도에 관한 사항\")]\n",
    "\n",
    "            if not match.empty:\n",
    "                url = match.iloc[0]['url']\n",
    "            else:\n",
    "                url = None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch for {corp} ({rcp}): {e}\")\n",
    "            url = None\n",
    "\n",
    "        results.append({\n",
    "            'corp_code': str(corp),\n",
    "            'corp_name': company,\n",
    "            'rcept_no': rcp,\n",
    "            'url': url,\n",
    "            'Total Assets (2022)': assets\n",
    "        })\n",
    "\n",
    "        time.sleep(0.7)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 3. Retrieve target audit committee document URLs for flagged cases\n",
    "audit_targets_df = missing_acm_urls(flagged).drop_duplicates(subset=['corp_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_update_audit_members(audit_targets_df, exec_df, summary_df):\n",
    "    \"\"\"\n",
    "    Parses financial documents for flagged corporations to find the table under\n",
    "    the '감사위원 현황' title to update audit committee member information.\n",
    "\n",
    "    Args:\n",
    "        audit_targets_df (pd.DataFrame): DataFrame of corporations flagged for\n",
    "                                         audit committee updates.\n",
    "        exec_df (pd.DataFrame): DataFrame containing executive information.\n",
    "        summary_df (pd.DataFrame): DataFrame containing summary information.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The updated exec_df and summary_df DataFrames.\n",
    "    \"\"\"\n",
    "    # Initialize necessary columns if they don't exist\n",
    "    for df in [exec_df, summary_df]:\n",
    "        if 'corp_code' in df.columns:\n",
    "            df['corp_code'] = df['corp_code'].astype(str)\n",
    "    \n",
    "    new_execs_to_add = []\n",
    "    summary_updates = {}\n",
    "\n",
    "    for idx, row in audit_targets_df.iterrows():\n",
    "        corp_code = str(row['corp_code'])\n",
    "        company = row['corp_name']\n",
    "        url = row['url']\n",
    "\n",
    "        if pd.isna(url) or not isinstance(url, str):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, timeout=20)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            members_found = []\n",
    "            auditors_found = []\n",
    "            \n",
    "            # --- SCENARIO 1: Find the table under a specific committee title ---\n",
    "            # Search for a header containing '감사위원 현황' or '감사위원회 위원의 인적사항'\n",
    "            ac_header_patterns = [\n",
    "                re.compile(r'감사위원\\s*현황'),\n",
    "                re.compile(r'감사위원회\\s*위원의\\s*인적사항'),\n",
    "                re.compile(r'감사위원회\\s*위원'),\n",
    "                re.compile(r'감사기구\\s*관련\\s*사항')\n",
    "            ]\n",
    "            \n",
    "            found_ac_section = None\n",
    "            ac_table = None\n",
    "            for pattern in ac_header_patterns:\n",
    "                found_ac_section = soup.find(string=pattern)\n",
    "                if found_ac_section:\n",
    "                    # Find the first table that comes after this specific header\n",
    "                    ac_table = found_ac_section.find_next('table')\n",
    "                    if ac_table:\n",
    "                        break\n",
    "            \n",
    "            if ac_table:\n",
    "                # Improved table parsing logic\n",
    "                headers = [th.get_text(strip=True).replace('\\xa0', '').replace('\\n', '') for tr in ac_table.find_all('tr', limit=2) for th in tr.find_all(['th', 'td'])]\n",
    "                name_idx = next((i for i, h in enumerate(headers) if '성명' in h), None)\n",
    "                outside_idx = next((i for i, h in enumerate(headers) if '사외이사' in h), None)\n",
    "                \n",
    "                if name_idx is not None and outside_idx is not None:\n",
    "                    # Prioritize tbody for finding data rows\n",
    "                    data_rows = ac_table.find_all('tbody')[0].find_all('tr') if ac_table.find('tbody') else ac_table.find_all('tr')[len(ac_table.find_all('tr', limit=2)):]\n",
    "                    for tr in data_rows:\n",
    "                        tds = tr.find_all(['td', 'th'])\n",
    "                        if len(tds) > max(name_idx, outside_idx):\n",
    "                            name = tds[name_idx].get_text(strip=True)\n",
    "                            is_outside = tds[outside_idx].get_text(strip=True)\n",
    "                            if name and name != '-' and '---' not in name:\n",
    "                                is_outside_flag = '예' in is_outside or 'O' in is_outside\n",
    "                                members_found.append({'name': name, 'is_outside': is_outside_flag})\n",
    "      \n",
    "                                        \n",
    "            # --- Finalize updates based on which scenario matched ---\n",
    "            if members_found:\n",
    "                total_members = len(members_found)\n",
    "                outside_members = sum(1 for member in members_found if member['is_outside'])\n",
    "                \n",
    "                for member in members_found:\n",
    "                    name = member['name']\n",
    "                    existing_mask = (exec_df['corp_code'] == corp_code) & (exec_df['nm'] == name)\n",
    "                    if not exec_df[existing_mask].empty:\n",
    "                        exec_df.loc[existing_mask, 'is_audit_committee_member'] = True\n",
    "                    else:\n",
    "                        new_execs_to_add.append({\n",
    "                            'corp_code': corp_code, 'corp_name': company, 'nm': name,\n",
    "                            'chrg_job': '감사위원회 위원', 'is_audit_committee_member': True\n",
    "                        })\n",
    "                \n",
    "                summary_updates[corp_code] = {\n",
    "                    'Audit Committee': total_members, 'Audit Committee ODs': outside_members,\n",
    "                }\n",
    "            else:\n",
    "                summary_updates[corp_code] = {\n",
    "                    'Audit Committee': 0, 'Audit Committee ODs': 0,\n",
    "                }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred for {corp_code} - {company}: {e}\")\n",
    "        time.sleep(0.7)\n",
    "    \n",
    "    for corp_code, update in summary_updates.items():\n",
    "        summary_df.loc[summary_df['corp_code'] == corp_code, 'Audit Committee'] = update['Audit Committee']\n",
    "        summary_df.loc[summary_df['corp_code'] == corp_code, 'Audit Committee ODs'] = update['Audit Committee ODs']\n",
    "        \n",
    "    return exec_df, summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d16277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 101220 - KG케미칼: No valid audit info found.\n",
      "✅ Updated 102432 - 계룡건설산업 with 3 audit committee members.\n",
      "✅ Updated 104856 - 삼성증권 with 3 audit committee members.\n",
      "✅ Updated 106669 - 세아베스틸지주 with 4 audit committee members.\n",
      "❌ 108135 - 녹십자홀딩스: No valid audit info found.\n",
      "✅ Updated 108241 - 농심 with 4 audit committee members.\n",
      "✅ Updated 111810 - 대웅 with 1 audit committee members.\n",
      "✅ Updated 113058 - 한화생명 with 3 audit committee members.\n",
      "✅ Updated 113191 - 코리안리 with 3 audit committee members.\n",
      "✅ Updated 113359 - 교보증권 with 3 audit committee members.\n",
      "❌ 113997 - 롯데에너지머티리얼즈: No valid audit info found.\n",
      "❌ 114792 - 동국홀딩스: No valid audit info found.\n",
      "✅ Updated 115694 - DB증권 with 3 audit committee members.\n",
      "✅ Updated 115977 - 아이에스동서 with 3 audit committee members.\n",
      "❌ 116949 - DN오토모티브: No valid audit info found.\n",
      "✅ Updated 117188 - 효성 with 3 audit committee members.\n",
      "✅ Updated 117577 - 오리온홀딩스 with 3 audit committee members.\n",
      "✅ Updated 120182 - NH투자증권 with 2 audit committee members.\n",
      "✅ Updated 121941 - 대상 with 4 audit committee members.\n",
      "❌ 124197 - 세아제강지주: No valid audit info found.\n",
      "❌ 125150 - SGC에너지: No valid audit info found.\n",
      "✅ Updated 126308 - 삼성E&A with 3 audit committee members.\n",
      "✅ Updated 126937 - 삼양홀딩스 with 4 audit committee members.\n",
      "✅ Updated 131054 - 유진증권 with 3 audit committee members.\n",
      "❌ 138701 - 아세아: No valid audit info found.\n",
      "✅ Updated 138792 - 아시아나항공 with 4 audit committee members.\n",
      "✅ Updated 139834 - LG씨엔에스 with 4 audit committee members.\n",
      "❌ 140964 - 영원무역홀딩스: No valid audit info found.\n",
      "✅ Updated 141307 - 영풍 with 3 audit committee members.\n",
      "✅ Updated 145109 - 유한양행 with 3 audit committee members.\n",
      "✅ Updated 145880 - 현대제철 with 4 audit committee members.\n",
      "❌ 148276 - 제일기획: No valid audit info found.\n",
      "✅ Updated 148610 - 한화투자증권 with 3 audit committee members.\n",
      "❌ 149646 - 기업은행: No valid audit info found.\n",
      "❌ 152862 - 코오롱: No valid audit info found.\n",
      "✅ Updated 153861 - 태영건설 with 3 audit committee members.\n",
      "✅ Updated 159023 - SK텔레콤 with 4 audit committee members.\n",
      "✅ Updated 159698 - 지역난방공사 with 3 audit committee members.\n",
      "✅ Updated 161976 - 한세예스24홀딩스 with 4 audit committee members.\n",
      "❌ 162063 - 한신공영: No valid audit info found.\n",
      "❌ 162993 - 한일홀딩스: No valid audit info found.\n",
      "✅ Updated 164478 - 현대건설 with 4 audit committee members.\n",
      "✅ Updated 164830 - HD한국조선해양 with 3 audit committee members.\n",
      "❌ 176914 - 다우기술: No valid audit info found.\n",
      "❌ 195229 - 미스토홀딩스: No valid audit info found.\n",
      "❌ 203315 - 콘텐트리중앙: No valid audit info found.\n",
      "❌ 225159 - SNT홀딩스: No valid audit info found.\n",
      "❌ 255619 - 강원랜드: No valid audit info found.\n",
      "✅ Updated 260383 - 대한유화 with 3 audit committee members.\n",
      "✅ Updated 261285 - 한국가스공사 with 3 audit committee members.\n",
      "✅ Updated 261443 - 엔씨소프트 with 3 audit committee members.\n",
      "✅ Updated 303873 - CJ CGV with 4 audit committee members.\n",
      "✅ Updated 339391 - 한화시스템 with 3 audit committee members.\n",
      "❌ 377610 - 세아홀딩스: No valid audit info found.\n",
      "✅ Updated 398701 - 엘앤에프 with 3 audit committee members.\n",
      "✅ Updated 500254 - GS with 3 audit committee members.\n",
      "✅ Updated 503668 - LIG넥스원 with 4 audit committee members.\n",
      "❌ 539274 - 대상홀딩스: No valid audit info found.\n",
      "✅ Updated 545716 - 롯데렌탈 with 2 audit committee members.\n",
      "✅ Updated 854997 - 에스디바이오센서 with 3 audit committee members.\n",
      "✅ Updated 877059 - 삼성바이오로직스 with 3 audit committee members.\n",
      "✅ Updated 896285 - 삼양사 with 3 audit committee members.\n",
      "✅ Updated 937324 - 한국타이어앤테크놀로지 with 3 audit committee members.\n",
      "❌ 939331 - 한국콜마: No valid audit info found.\n",
      "✅ Updated 983040 - 한진칼 with 3 audit committee members.\n",
      "❌ 990165 - 아세아시멘트: No valid audit info found.\n",
      "✅ Updated 1060744 - 한솔제지 with 3 audit committee members.\n",
      "✅ Updated 1133217 - 카카오뱅크 with 3 audit committee members.\n",
      "✅ Updated 1310269 - HDC현대산업개발 with 3 audit committee members.\n",
      "✅ Updated 1316236 - 효성화학 with 3 audit committee members.\n",
      "✅ Updated 1316254 - HS효성첨단소재 with 3 audit committee members.\n",
      "❌ 1363818 - 롯데리츠: No valid audit info found.\n",
      "✅ Updated 1390344 - HD현대중공업 with 3 audit committee members.\n",
      "❌ 1415892 - 제이알글로벌리츠: No valid audit info found.\n",
      "❌ 1437186 - ESR켄달스퀘어리츠: No valid audit info found.\n",
      "❌ 1535150 - SK리츠: No valid audit info found.\n",
      "Original exec_df is unchanged.\n",
      "Original summary_df is unchanged.\n"
     ]
    }
   ],
   "source": [
    "exec_df, summary_df = parse_and_update_audit_members(\n",
    "    audit_targets_df,\n",
    "    exec_df,\n",
    "    summary_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Governance Compliance Check Results ---\n",
      "\n",
      "✅ Corporations with a single auditor (no audit committee):\n",
      "  - KG케미칼 (Auditor: 1)\n",
      "  - 녹십자홀딩스 (Auditor: 1)\n",
      "  - 롯데에너지머티리얼즈 (Auditor: 1)\n",
      "  - 동국홀딩스 (Auditor: 1)\n",
      "  - DN오토모티브 (Auditor: 1)\n",
      "  - 세아제강지주 (Auditor: 1)\n",
      "  - SGC에너지 (Auditor: 1)\n",
      "  - 아세아 (Auditor: 1)\n",
      "  - 영원무역홀딩스 (Auditor: 1)\n",
      "  - 제일기획 (Auditor: 1)\n",
      "  - 기업은행 (Auditor: 1)\n",
      "  - 코오롱 (Auditor: 1)\n",
      "  - 한신공영 (Auditor: 1)\n",
      "  - 한일홀딩스 (Auditor: 1)\n",
      "  - 다우기술 (Auditor: 1)\n",
      "  - 미스토홀딩스 (Auditor: 1)\n",
      "  - 콘텐트리중앙 (Auditor: 1)\n",
      "  - SNT홀딩스 (Auditor: 1)\n",
      "  - 강원랜드 (Auditor: 1)\n",
      "  - 세아홀딩스 (Auditor: 2)\n",
      "  - 대상홀딩스 (Auditor: 1)\n",
      "  - 한국콜마 (Auditor: 2)\n",
      "  - 아세아시멘트 (Auditor: 1)\n",
      "  - 제이알글로벌리츠 (Auditor: 2)\n",
      "  - ESR켄달스퀘어리츠 (Auditor: 2)\n",
      "-----------------------------------------\n",
      "\n",
      "⚠️ Corporations with a partial audit committee (< 3 members):\n",
      "  - 대웅 (Members: 1)\n",
      "  - NH투자증권 (Members: 2)\n",
      "  - 롯데렌탈 (Members: 2)\n",
      "-----------------------------------------\n",
      "\n",
      "❌ Corporations with no audit committee or auditor found:\n",
      "  - 롯데리츠\n",
      "  - SK리츠\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Assuming summary_df_updated is your updated DataFrame\n",
    "check_2 = check_governance_compliance(summary_df)\n",
    "\n",
    "print(\"--- Governance Compliance Check Results ---\")\n",
    "\n",
    "# Print corporations with a single auditor (no audit committee)\n",
    "no_ac_but_auditor = check_2[(check_2['Audit Committee'] == 0) & (check_2['Auditors'] > 0)]\n",
    "if not no_ac_but_auditor.empty:\n",
    "    print(\"\\nCorporations with a single auditor (no audit committee):\")\n",
    "    for index, row in no_ac_but_auditor.iterrows():\n",
    "        print(f\"  - {row['corp_name']} (Auditor: {row['Auditors']})\")\n",
    "else:\n",
    "    print(\"\\nNo corporations found with a single auditor (no audit committee).\")\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "# Print corporations with a partial audit committee (< 3 members)\n",
    "partial_ac = check_2[((check_2['Audit Committee'] > 0) & (check_2['Audit Committee'] < 3))]\n",
    "if not partial_ac.empty:\n",
    "    print(\"\\nCorporations with a partial audit committee (< 3 members):\")\n",
    "    for index, row in partial_ac.iterrows():\n",
    "        print(f\"  - {row['corp_name']} (Members: {row['Audit Committee']})\")\n",
    "else:\n",
    "    print(\"\\nNo corporations found with a partial audit committee.\")\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "# Print corporations with no audit committee or auditor found\n",
    "no_ac_no_auditor = check_2[(check_2['Audit Committee'] == 0) & (check_2['Auditors'] == 0)]\n",
    "if not no_ac_no_auditor.empty:\n",
    "    print(\"\\nCorporations with no audit committee or auditor found:\")\n",
    "    for index, row in no_ac_no_auditor.iterrows():\n",
    "        print(f\"  - {row['corp_name']}\")\n",
    "else:\n",
    "    print(\"\\nNo corporations found with neither an audit committee nor an auditor.\")\n",
    "\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d421ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_career_refined(career_string):\n",
    "    if pd.isna(career_string):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    education = []\n",
    "    work_experience = []\n",
    "    \n",
    "    # Prioritized keywords\n",
    "    job_keywords = ['교수', '총장', '강사', '연구원', '학장', '팀장', '실장', '감사', '대표', '회장', '이사'] \n",
    "    edu_keywords = ['학사', '석사', '박사', '대학교', '법학', '대학원', '졸업', '수료', 'Univ.', 'School', 'College', 'MBA', 'U.', 'Institute', 'University']\n",
    "\n",
    "    career_items = career_string.split('\\n')\n",
    "    \n",
    "    for item in career_items:\n",
    "        # Step 1: Check for job keywords first\n",
    "        if any(keyword in item for keyword in job_keywords):\n",
    "            work_experience.append(item.strip())\n",
    "        # Step 2: If no job keywords, check for educational keywords\n",
    "        elif any(keyword in item for keyword in edu_keywords):\n",
    "            education.append(item.strip())\n",
    "        # Step 3: Default to work experience for other entries\n",
    "        else:\n",
    "            work_experience.append(item.strip())\n",
    "            \n",
    "    return (\n",
    "        '\\n'.join(education) if education else np.nan,\n",
    "        '\\n'.join(work_experience) if work_experience else np.nan\n",
    "    )\n",
    "\n",
    "exec_df[['Education', 'Work Experience']] = exec_df['main_career'].apply(\n",
    "    lambda x: pd.Series(separate_career_refined(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "351692c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {\n",
    "    'rcept_no': 'Disclosure',\n",
    "    'nm': 'Name',\n",
    "    'sexdstn': 'Gender',\n",
    "    'ofcps': 'Position',\n",
    "    'rgist_exctv_at': 'Status',\n",
    "    'chrg_job': 'Responsibilities',\n",
    "    'mxmm_shrholdr_relate': 'Relation to Largest Shareholder',\n",
    "    'hffc_pd': 'Employment Period',\n",
    "    'trmend_posesn_stock_qota_rt': 'Stock Owned'\n",
    "}\n",
    "\n",
    "exec_df = exec_df.rename(columns=new_names).drop(columns=['main_career'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2db90e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'data/processed'\n",
    "exec_file_path = os.path.join(output_folder, 'exec_df.csv')\n",
    "summary_file_path = os.path.join(output_folder, 'summary_df.csv')\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "exec_df.to_csv(exec_file_path, index=False, encoding='utf-8-sig')\n",
    "summary_df.to_csv(summary_file_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a1a8f4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rcept_no</th>\n",
       "      <th>corp_cls</th>\n",
       "      <th>corp_code</th>\n",
       "      <th>corp_name</th>\n",
       "      <th>nmpr</th>\n",
       "      <th>jan_avrg_mendng_am</th>\n",
       "      <th>mendng_totamt</th>\n",
       "      <th>rm</th>\n",
       "      <th>stlm_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250313001154</td>\n",
       "      <td>Y</td>\n",
       "      <td>173944</td>\n",
       "      <td>우진</td>\n",
       "      <td>7</td>\n",
       "      <td>712,026,000</td>\n",
       "      <td>4,984,181,000</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250318001356</td>\n",
       "      <td>Y</td>\n",
       "      <td>109286</td>\n",
       "      <td>대동</td>\n",
       "      <td>7</td>\n",
       "      <td>427,000,000</td>\n",
       "      <td>2,992,000,000</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20250313000953</td>\n",
       "      <td>Y</td>\n",
       "      <td>129350</td>\n",
       "      <td>삼화콘덴서공업</td>\n",
       "      <td>9</td>\n",
       "      <td>235,095,000</td>\n",
       "      <td>2,115,856,000</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20250320001552</td>\n",
       "      <td>Y</td>\n",
       "      <td>144252</td>\n",
       "      <td>유니온</td>\n",
       "      <td>5</td>\n",
       "      <td>286,000,000</td>\n",
       "      <td>1,431,000,000</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20250321000814</td>\n",
       "      <td>Y</td>\n",
       "      <td>303217</td>\n",
       "      <td>우진플라임</td>\n",
       "      <td>5</td>\n",
       "      <td>188,070,000</td>\n",
       "      <td>940,351,000</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>20250320001708</td>\n",
       "      <td>Y</td>\n",
       "      <td>108746</td>\n",
       "      <td>DKME</td>\n",
       "      <td>6</td>\n",
       "      <td>67,000,000</td>\n",
       "      <td>403,000,000</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>20250320001204</td>\n",
       "      <td>Y</td>\n",
       "      <td>1262032</td>\n",
       "      <td>롯데이노베이트</td>\n",
       "      <td>7</td>\n",
       "      <td>416,000,000</td>\n",
       "      <td>2,911,000,000</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>20250319000718</td>\n",
       "      <td>Y</td>\n",
       "      <td>136776</td>\n",
       "      <td>제이준코스메틱</td>\n",
       "      <td>10</td>\n",
       "      <td>18,730,000</td>\n",
       "      <td>187,300,000</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>20250317000666</td>\n",
       "      <td>Y</td>\n",
       "      <td>114154</td>\n",
       "      <td>디와이덕양</td>\n",
       "      <td>10</td>\n",
       "      <td>167,000,000</td>\n",
       "      <td>1,667,000,000</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>20250331003521</td>\n",
       "      <td>Y</td>\n",
       "      <td>102858</td>\n",
       "      <td>고려아연</td>\n",
       "      <td>13</td>\n",
       "      <td>468,000,000</td>\n",
       "      <td>6,078,000,000</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>870 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rcept_no corp_cls  corp_code corp_name  nmpr jan_avrg_mendng_am  \\\n",
       "0    20250313001154        Y     173944        우진     7        712,026,000   \n",
       "1    20250318001356        Y     109286        대동     7        427,000,000   \n",
       "2    20250313000953        Y     129350   삼화콘덴서공업     9        235,095,000   \n",
       "3    20250320001552        Y     144252       유니온     5        286,000,000   \n",
       "4    20250321000814        Y     303217     우진플라임     5        188,070,000   \n",
       "..              ...      ...        ...       ...   ...                ...   \n",
       "865  20250320001708        Y     108746      DKME     6         67,000,000   \n",
       "866  20250320001204        Y    1262032   롯데이노베이트     7        416,000,000   \n",
       "867  20250319000718        Y     136776   제이준코스메틱    10         18,730,000   \n",
       "868  20250317000666        Y     114154     디와이덕양    10        167,000,000   \n",
       "869  20250331003521        Y     102858      고려아연    13        468,000,000   \n",
       "\n",
       "     mendng_totamt rm     stlm_dt  \n",
       "0    4,984,181,000  -  2024-12-31  \n",
       "1    2,992,000,000  -  2024-12-31  \n",
       "2    2,115,856,000  -  2024-12-31  \n",
       "3    1,431,000,000  -  2024-12-31  \n",
       "4      940,351,000  -  2024-12-31  \n",
       "..             ... ..         ...  \n",
       "865    403,000,000  -  2024-12-31  \n",
       "866  2,911,000,000  -  2024-12-31  \n",
       "867    187,300,000  -  2024-12-31  \n",
       "868  1,667,000,000  -  2024-12-31  \n",
       "869  6,078,000,000  -  2024-12-31  \n",
       "\n",
       "[870 rows x 9 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8038e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_df = pd.read_csv(r'C:\\Program Files\\Git\\OPENDART\\governance_scoring_proj\\notebooks\\data\\processed\\exec_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
