{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00a8b05",
   "metadata": {},
   "source": [
    "# **Governance Database Extraction and Preprocessing**\n",
    "\n",
    "Governance Database Proj retrieves data directly from OPENDART to build a database of KOSPI-listed corporations and their executives.\n",
    "\n",
    "For stability, information is pulled directly from OPENDART API where possible. Almost all OPENDART requests require a single API call per corporation or report request, which is reflected in the total execution time. Only one function relies on OpenDartReader to search for direct links to audit committee information, which is used for making updates to flagged cases in preprocessing. \n",
    "\n",
    "[OPENDART API limits](https://engopendart.fss.or.kr/cop/bbs/selectArticleDetail.do) are as follows: \n",
    "- Individual: 20,000 calls a day (the limit is for all 83 API services and not by service)\n",
    "- Corporation (business registration and registered IP)\n",
    "    - 2 services (\"Search disclosures\" and \"Overview of corporate status\"): Unlimited\n",
    "    - 81 services (excluding \"Search disclosures\" and \"Overview of corporate status\"): 20,000 calls a day (the limit is for all 81 API services and not by service)\n",
    "- 1,000 calls per minute\n",
    "\n",
    "### Environment Set Up \n",
    "This notebook was created using Python 3.13.5. The cell below will check that the current kernel is using the same or updated Python version and raise an error otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d23a744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 13, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca9e5e",
   "metadata": {},
   "source": [
    "### Outputs\n",
    "\n",
    "By the end of the project, the following two databases will be saved: \n",
    "1. **executive_df**, providing details on the 15k+ listed executives, including information such as registered officer status, shareholder relations, salary, and professional experience.\n",
    "\n",
    "2. **summary_df**,  a grouped dataset across corp-level information, including number of director types, audit committee size, and total assets from the past three years (used to determine audit committee mandate).\n",
    "\n",
    "*navigate to README.md file for reference*\n",
    "\n",
    "The raw data, pulled from OPENDART and used to build the two dataframes are also saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6701c639",
   "metadata": {},
   "source": [
    "### Internal Packages \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b620bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import zipfile \n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "from concurrent.futures import ThreadPoolExecutor \n",
    "\n",
    "import dart_fss\n",
    "import OpenDartReader "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6063c1",
   "metadata": {},
   "source": [
    "### Internal Packages \n",
    "\n",
    "Update **API_key**, **bsns_year**, **reprt_code**, and  **reference_date** as needed.\n",
    "\n",
    "OPENDART reprt_code: \n",
    "- First Quarterly Report : 11013\n",
    "- Semi-annual Report : 11012\n",
    "- Third Quarterly Report : 11014\n",
    "- Annual Report : 11011\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "193ca248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0d67945133e224c451452e071e0d8349969353e1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_key = '0d67945133e224c451452e071e0d8349969353e1' \n",
    "bsns_year = '2024'\n",
    "reprt_code = '11011'\n",
    "reference_date = datetime(2025, 8, 12) # used for tenure calculation\n",
    "\n",
    "dart = OpenDartReader(API_key)\n",
    "dart_fss.set_api_key(API_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f819811",
   "metadata": {},
   "source": [
    "### **Data Extraction**\n",
    "\n",
    "Produces all the raw data files necessary for preprocessing. All 7 csv files are saved in the raw data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd52efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_DIR = os.path.join('..', 'data', 'raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5cbc9",
   "metadata": {},
   "source": [
    "#### 0. save_df_to_csv\n",
    "</b>\n",
    "\n",
    "a helper function, called at the end of each function to save outputs as csv files within raw data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4945b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_csv(df: pd.DataFrame, file_path: str, index: bool = False):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    try:\n",
    "        df.to_csv(file_path, index=index)\n",
    "        print(f\"DataFrame saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving DataFrame to CSV {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee79881",
   "metadata": {},
   "source": [
    "#### 1. get_corp_code\n",
    "</b>\n",
    "\n",
    "\n",
    "pulls the most up to date list of corp codes with a single API call to the OPENDART zip file. Corp codes are unique reference codes assigned by OPENDART, distinct from stock number and used as required keys to access and pull full company (2. get_kospi_company_info) and executive (3. get_executive_status_data) info. \n",
    "</b>\n",
    "\n",
    "[OPENDART | Guide for Developers to Corporation code](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE001&apiId=AE00004)\n",
    "</b>\n",
    "\n",
    "Required Key: \n",
    "</b>\n",
    "\n",
    "- crtfc_key (API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f963c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corp_code(api_key: str, output_dir: str = BASE_DATA_DIR) -> pd.DataFrame:\n",
    "    url_code = f'https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={api_key}'\n",
    "    response = requests.get(url_code) \n",
    "\n",
    "    # check that the target directory exists \n",
    "    os.makedirs('dart_data', exist_ok=True)\n",
    "\n",
    "    # unzip and extract CORPCODE.xml\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        z.extractall('dart_data')\n",
    "        xml_path = os.path.join('dart_data', 'CORPCODE.xml')\n",
    "\n",
    "    # parse XML\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # filter for listed companies (6-digit stock code only) and append to df\n",
    "    corp_list = []\n",
    "    for corp in root.findall('list'):\n",
    "        stock_code = corp.findtext('stock_code')\n",
    "        if stock_code and len(stock_code) == 6:\n",
    "            corp_list.append({\n",
    "                'corp_code': corp.findtext('corp_code'),\n",
    "                'corp_name': corp.findtext('corp_name'),\n",
    "                'corp_eng_name': corp.findtext('corp_eng_name'),\n",
    "                'stock_code': stock_code\n",
    "            })\n",
    "\n",
    "    #save in raw data folder \n",
    "    corp_codes_df = pd.DataFrame(corp_list)\n",
    "    output_filepath = os.path.join(output_dir, 'listed_corp_codes.csv')\n",
    "    save_df_to_csv(corp_codes_df, output_filepath)\n",
    "    return corp_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8057e06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to ..\\data\\raw\\listed_corp_codes.csv\n"
     ]
    }
   ],
   "source": [
    "all_corp_codes_df = get_corp_code(API_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3fde21",
   "metadata": {},
   "source": [
    "#### 2. get_kospi_company_info\n",
    "</b>\n",
    "\n",
    "passes in the list of corp codes from get_corp_code, filters for kospi codes, and fetches all detailed company info. OPENDART requires an individual call for each *corp_code*, resulting in a total execution time of: ~ 9 minutes for 3,000+ calls.\n",
    "\n",
    "[OPENDART | Guide for Developers to Overview of corporate status](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE001&apiId=AE00002)\n",
    "\n",
    "Required Keys: \n",
    "- crtfc_key (API key) \n",
    "- corp_code \n",
    "\n",
    "Kept Data: \n",
    "</b>\n",
    "\n",
    "\n",
    "| Key  | Name | \n",
    "| -------|-----|\n",
    "| corp_name | Formal name\t  | \n",
    "| stock_code  | Stock item code\t  | \n",
    "| ceo_nm  | Representative name  |\n",
    "| induty_code*  |  Industry code   | \n",
    "\n",
    "*induty_code: not relevant now, could be used later to compare industry norms\n",
    "\n",
    "Dropped Data (corp code and name are sufficient for identification):\n",
    "| Key  | Name |\n",
    "| -------|-----|\n",
    "| corp_name_eng  | English name\t  | \n",
    "| stock_name | Item name \t  | \n",
    "| corp_cls  |  Corporation type   | \n",
    "| jurir_no  |  Corporate registration No.   |\n",
    "| bizr_no | Business registration No.  | \n",
    "| adres | Address  | \n",
    "| hm_url  | Website URL  | \n",
    "| ir_url  | IR website  | \n",
    "| phn_no |  Telephone No.   | \n",
    "| fax_no  | Fax No.  | \n",
    "| est_dt  | Establishment date (YYYYMMDD)  | \n",
    "| acc_mt  | Month of settlement (MM)  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebbf895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kospi_company_info(api_key: str, corp_codes_df: pd.DataFrame, output_dir: str = BASE_DATA_DIR) -> pd.DataFrame:\n",
    "    data = []\n",
    "    api_endpoint = \"https://engopendart.fss.or.kr/engapi/company.json\"\n",
    "\n",
    "    for i, row in corp_codes_df.iterrows(): # iterate over list of corp_codes\n",
    "        corp_code = row['corp_code']\n",
    "        corp_name = row['corp_name']\n",
    "\n",
    "        params = { # OPENDART required keys\n",
    "            'crtfc_key': API_key,\n",
    "            'corp_code': corp_code\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(api_endpoint, params=params)\n",
    "            response.raise_for_status() # raise HTTPError for bad responses \n",
    "            info = response.json()\n",
    "\n",
    "            # filter for KOSPI companies \n",
    "            if info and info.get('corp_cls') == 'Y': # all types: Y (KOSPI), K (KOSDAQ), N (KONEX), E (Other)\n",
    "                data.append({\n",
    "                    'corp_name': info.get('corp_name'),\n",
    "                    'corp_code': info.get('corp_code'),\n",
    "                    'stock_code': info.get('stock_code'),\n",
    "                    'ceo_name': info.get('ceo_nm'),\n",
    "                    'industry_code': info.get('induty_code'),\n",
    "                })\n",
    "            time.sleep(0.07) # respect API limit\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch company info for {corp_name} ({corp_code}): {e}\")\n",
    "            continue\n",
    "    \n",
    "    # save in raw data folder\n",
    "    kospi_codes_df = pd.DataFrame(data)\n",
    "    output_filepath = os.path.join(output_dir, 'kospi_company_info.csv')\n",
    "    save_df_to_csv(kospi_codes_df, output_filepath)\n",
    "    return kospi_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e67499e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to ..\\data\\raw\\kospi_company_info.csv\n"
     ]
    }
   ],
   "source": [
    "kospi_company_info_df = get_kospi_company_info(api_key=API_key, corp_codes_df=all_corp_codes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44028172",
   "metadata": {},
   "source": [
    "#### 3. get_executive_status_data\n",
    "\n",
    "retrieves executive-level data by passing in the list of KOSPI listed corps. OPENDART requires an individual API call per corporation, with 850 calls ~ 2 minutes.\n",
    "As the function iterates over the KOSPI corps, it flags any where no executive data is available.\n",
    "\n",
    "[OPENDART | Guide for Developers to Status of executives](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00011)\n",
    "\n",
    "Required Keys:\n",
    "- crtfc_key (API key)\n",
    "- corp_code \n",
    "- bsns_year (fiscal year)\n",
    "- reprt_code\n",
    "    - First Quarterly Report : 11013\n",
    "    - Semi-annual Report : 11012\n",
    "    - Third Quarterly Report : 11014\n",
    "    - Annual Report : 11011\n",
    "\n",
    "The resulting **executive_status_data_df** saves all the information available. In preprocessing, **exec_df** filters down based on the following: \n",
    "\n",
    "Kept Data: \n",
    "| Key  | Name | \n",
    "| -------|-----|\n",
    "| rcept_no | Filing No.  | \n",
    "| corp_cls | Corporation type\t  |\n",
    "| corp_code | Corporation code\t  | \n",
    "| corp_name | Corporation name\t  | \n",
    "| nm | Name  |\n",
    "| sexdstn | Gender  | \n",
    "| ofcps | Position  | \n",
    "| rgist_exctv_at | Registered officer status  | \n",
    "| fte_at | Full-time  | \n",
    "| chrg_job | Responsibilites  | \n",
    "| main_career | Professional Background  |\n",
    "| mxmm_shrholdr_relate | Relationship to Largest Shareholder  | \n",
    "| hffc_pd | Period of employment  | \n",
    "\n",
    "Dropped Data: \n",
    "| Key  | Name | \n",
    "| -------|-----|\n",
    "| birth_ym | Date of birth  | \n",
    "| tenure_end_on | Term expiration date  | \n",
    "| stlm_dt | Settlement date  | \n",
    "\n",
    "As tenure in company is sufficient for guaging expertise and *stlm_dt* is irrelevant given filter for year and report type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a31a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_executive_status_data(api_key: str, kospi_codes_df: pd.DataFrame, bsns_year: int, reprt_code: str, output_dir: str = BASE_DATA_DIR) -> pd.DataFrame:\n",
    "    results = []\n",
    "    api_endpoint = \"https://opendart.fss.or.kr/api/exctvSttus.json\"\n",
    "\n",
    "    for idx, row in kospi_codes_df.iterrows():\n",
    "        corp_code = row['corp_code']\n",
    "        corp_name = row['corp_name']\n",
    "        stock_code = row['stock_code']\n",
    "\n",
    "        params = { #OPENDART required keys\n",
    "            'crtfc_key': api_key,\n",
    "            'corp_code': corp_code,\n",
    "            'bsns_year': bsns_year,\n",
    "            'reprt_code': reprt_code\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(api_endpoint, params=params)\n",
    "            response.raise_for_status() # raise error for bad responses \n",
    "            data = response.json()\n",
    "\n",
    "            if data['status'] == '000': # success - data found\n",
    "                if 'list' in data and data['list']:\n",
    "                    df = pd.DataFrame(data['list']) # appends all info, later filtered down in preprocessing\n",
    "                    df['stock_code'] = stock_code\n",
    "                    \n",
    "                    results.append(df)\n",
    "            else:\n",
    "                print(f\"No executive data available for {corp_name} ({corp_code}) for {bsns_year}/{reprt_code}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred for {corp_name} ({corp_code}): {e}\")\n",
    "\n",
    "        time.sleep(0.07) \n",
    "\n",
    "    if results:\n",
    "        executive_status_df = pd.concat(results, ignore_index=True)\n",
    "        output_filepath = os.path.join(output_dir, f'executive_status_{bsns_year}_{reprt_code}.csv')\n",
    "        save_df_to_csv(executive_status_df, output_filepath)\n",
    "        return executive_status_df\n",
    "    else:\n",
    "        print(\"\\nNo executive status data was retrieved.\")\n",
    "        return pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "646dd740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No executive data available for 미래에셋맵스 아시아퍼시픽 부동산공모 1호 투자회사 (00600013) for 2024/11011.\n",
      "No executive data available for 맥쿼리한국인프라투융자회사 (00435297) for 2024/11011.\n",
      "No executive data available for 한국투자ANKOR유전해외자원개발특별자산투자회사1호(지분증권) (00907013) for 2024/11011.\n",
      "No executive data available for 케이비발해인프라투융자회사 (01880801) for 2024/11011.\n",
      "No executive data available for 대원강업(주) (00111847) for 2024/11011.\n",
      "No executive data available for 주식회사 대신밸류리츠위탁관리부동산투자회사 (01885222) for 2024/11011.\n",
      "No executive data available for 대한조선 주식회사 (00182696) for 2024/11011.\n",
      "DataFrame saved to data\\raw\\executive_status_2024_11011.csv\n"
     ]
    }
   ],
   "source": [
    "executive_status_data_df = get_executive_status_data(API_key, kospi_company_info_df, bsns_year, reprt_code) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adbaf87",
   "metadata": {},
   "source": [
    "#### 4. get_total_assets  \n",
    "\n",
    "makes requests to OPENDART's financial statements API to pull total assets from each corp. For each corp, if a consolidated report ('CFS') exists, it pulls information from that statement. Otherwise, it falls back on the separate report ('OFS'). The function supports pulling other FS data, as long as sj_div and sj_nm are located correctly, and *target_account_names* is updated to reflect the target key words. The full function makes 850 (length of KOSPI codes) calls, with execution time ~ 3 minutes.\n",
    "\n",
    "\n",
    "[OPENDART | Single company’s full financial statements 개발가이드](https://opendart.fss.or.kr/guide/detail.do?apiGrpCd=DE003&apiId=AE00036)\n",
    "\n",
    "Required Keys:\n",
    "- crtfc_key (API key)\n",
    "- corp_code \n",
    "- bsns_year (fiscal year)\n",
    "- reprt_code \n",
    "- fs_div (seperate/consolidated report)\n",
    "\n",
    "The resulting **assets_YYYY_REPORT**  will be used to check requirements for mandated audit committees (corporations with total assets > $2T KRW). Because corporations have a two year grace period for forming a mandated audit committee, the function pulls total assets from the past three years. \n",
    "\n",
    "Kept Data: \n",
    "| Key  | Name | \n",
    "| -------|-----|\n",
    "| rcept_no* | Filing No.  | \n",
    "| thstrm_amount\t| Term amount |\n",
    "| frmtrm_amount\t| Previous term amount | \n",
    "| bfefrmtrm_amount\t| Amount of term before previous | \n",
    "\n",
    "Dropped Data: \n",
    "| Key  | Name | \n",
    "| -------|-----|\n",
    "| reprt_code | Report code\t  | \n",
    "| bsns_year | Fiscal year\t  | \n",
    "| corp_code | Corporation code\t  | \n",
    "| sj_div** | Type of financial statement\t  |\n",
    "| sj_nm | Financial statement title\t  |\n",
    "| account_id | Account ID  |\n",
    "| account_nm | Account name  | \n",
    "| account_detail | Detail account  |\n",
    "| thstrm_nm\t| Term name  | \n",
    "| thstrm_add_amount\t | Accumulated term amount\t  | \n",
    "| frmtrm_nm\t| Previous term name | \n",
    "| frmtrm_q_nm | Previous term name(Quarterly/Semiannual) | \n",
    "| frmtrm_q_amount | Previous term amount(Quarterly/Semiannual) | \n",
    "| frmtrm_add_amount\t| Accumulated previous term amount  | \n",
    "| bfefrmtrm_nm\t| Name of term before previous | \n",
    "| ord\t| Account code sort order | \n",
    "| currency\t| Currency unit |\n",
    "\n",
    "*required key for subdoc searches in preprocessing\n",
    "\n",
    "**function already filters for sj_div = BS, can change to retrieve data from other statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca9c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_assets(kospi_company_info_df: pd.DataFrame, bsns_year: str, reprt_code: str, API_key: str, output_dir: str = BASE_DATA_DIR) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches Total Assets for a list of companies from the DART API without helper functions.\n",
    "    \"\"\"\n",
    "    api_url = 'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json'\n",
    "    target_sj_div = \"BS\"\n",
    "    target_account_names = {\"자산총계\", \"총자산\", \"자산\"} # checks for possible categories covering total assets \n",
    "    year = int(bsns_year)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for corp_code in kospi_company_info_df['corp_code']:\n",
    "        rcept_no, assets, prior_assets, two_years_ago = None, None, None, None\n",
    "        \n",
    "        # try CFS first, fall back on OFS\n",
    "        for fs_div in ['CFS', 'OFS']:\n",
    "            params = {'crtfc_key': API_key, 'corp_code': corp_code, 'bsns_year': bsns_year, 'reprt_code': reprt_code, 'fs_div': fs_div}\n",
    "            try:\n",
    "                res = requests.get(api_url, params=params)\n",
    "                res.raise_for_status()\n",
    "                data = res.json()\n",
    "                \n",
    "                if data.get('status') == '000' and 'list' in data:\n",
    "                    # search for assets data directly from the JSON list\n",
    "                    for item in data['list']:\n",
    "                        if item['sj_div'] == target_sj_div and item['account_nm'].strip().replace(' ', '') in target_account_names:\n",
    "                            rcept_no = item.get('rcept_no')\n",
    "                            assets = pd.to_numeric(item.get('thstrm_amount', '').replace(',', ''), errors='coerce')\n",
    "                            prior_assets = pd.to_numeric(item.get('frmtrm_amount', '').replace(',', ''), errors='coerce')\n",
    "                            two_years_ago = pd.to_numeric(item.get('bfefrmtrm_amount', '').replace(',', ''), errors='coerce')\n",
    "                            break \n",
    "                    \n",
    "                    if assets is not None:\n",
    "                        break \n",
    "            \n",
    "            except (requests.exceptions.RequestException, ValueError):\n",
    "                continue\n",
    "        \n",
    "        if assets is None:\n",
    "            print(f\"Total Assets not found for {corp_code}.\")\n",
    "\n",
    "        all_results.append({ # where asset data is found, append all listed years with the correct label\n",
    "            'corp_code': corp_code,\n",
    "            'rcept_no': rcept_no,\n",
    "            f'{year}_total_assets': assets,\n",
    "            f'{year - 1}_total_assets': prior_assets,\n",
    "            f'{year - 2}_total_assets': two_years_ago\n",
    "        })\n",
    "        \n",
    "        time.sleep(0.07)\n",
    "\n",
    "    assets_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    for y_offset in [0, 1, 2]:\n",
    "        col_name = f'{year - y_offset}_total_assets'\n",
    "        if col_name in assets_df.columns:\n",
    "            assets_df[col_name] = pd.to_numeric(assets_df[col_name], errors='coerce').astype('Int64')\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"assets_{bsns_year}_{reprt_code}.csv\")\n",
    "    assets_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    return assets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2dca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_df = get_total_assets(kospi_company_info_df, bsns_year, reprt_code, API_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036bd84d",
   "metadata": {},
   "source": [
    "#### 5. get_salary_type\n",
    "\n",
    "pulls salary data from three OPDENDART source types: \n",
    "- Individual, which discloses the exact amount for executives making more than 500M KRW. \n",
    "- Grouped, which provides total annual grouped salary and average salaries by status type. \n",
    "- Unregistered, which provides the total annual grouped salary and average per person.\n",
    "\n",
    "In the preprocessing notebook, salary is appended to each executive - exact where possible and average amounts otherwise. Because there are three separate API endpoints, **get_salary_type** contains two internal helper functions: **_get_json** and **_get_salary_data_for_corp**. When the main function is called, the list of KOSPI *corp_codes* is passed as keys to **_get_salary_data_for_corp**, which makes separate calls to each source type using **_get_json**. All the disclosed datapoints are then appended to a larger, consolidated dataframe saved as **salary_data_YYYY_REPORT** in the raw data folder, and refered to within this notebook as **salary_separate_df**. If any errors occur in retrieving a corp's data, the details will be flagged and printed. \n",
    "\n",
    "1. [OPENDART | Guide for Developers to Remuneration for individual directors and auditors](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00013) (lists all those > 500m KRW)\n",
    "\n",
    "2. [OPENDART | Guide for Developers to Remuneration for all directors and auditors (remuneration paid - by type)](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00030)\n",
    "\n",
    "3. [OPENDART | Guide for Developers to Remuneration for unregistered executives](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00028)\n",
    "\n",
    "Required Keys:\n",
    "- crtfc_key (API key)\n",
    "- corp_code \n",
    "- bsns_year (fiscal year)\n",
    "- reprt_code \n",
    "\n",
    "The resulting **salary_separate_df** displays the salary data pulled from the three datapoints, with standardized columns for the purposes of merging with **exec_df** in the preprocessing notebook. The following chart maps the resulting **salary_separate_df**'s column names to the corresponding OPENDART source.\n",
    "\n",
    "| salary_separate_df column  | (1.) Individual | (2.) All By Type | (3.) Unregistered | \n",
    "| -------|-----|-----|-----|\n",
    "| position | ofcps | se (category)* | se\t(unregistered) |\n",
    "| compensation | mendng_totamt | psn1_avrg_pymntamt | jan_salary_am |\n",
    "| salary_source | 개인별보수 | 임원전체보수유형 | 미등기임원 |\n",
    "| salary_type | exact | estimate | estimate | \n",
    "\n",
    "\n",
    "*category 'types':\n",
    "\n",
    "- Registered director (excluding outside directors and members of the audit committee)\n",
    "- Outside director (excluding members of the audit committee)\n",
    "- Member of the audit committee\n",
    "- Auditors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e8c5ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary_type(kospi_company_info_df: pd.DataFrame, bsns_year: str, reprt_code: str, API_key: str, output_dir: str = BASE_DATA_DIR) -> pd.DataFrame:\n",
    "    # internal helper function to pull json requests \n",
    "    def _get_json(url, corp_code):\n",
    "        params = {\n",
    "            'crtfc_key': API_key,\n",
    "            'corp_code': corp_code,\n",
    "            'bsns_year': bsns_year,\n",
    "            'reprt_code': reprt_code\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get('status') != '000' or 'list' not in data:\n",
    "                if data.get('status') != '000':\n",
    "                    print(f\"OPENDART Error for {corp_code}: {data.get('message')}\")\n",
    "                return []\n",
    "            return data['list']\n",
    "        except Exception as e:\n",
    "            print(f\"Request failed for {url} with params {params}: {e}\")\n",
    "            return []\n",
    "\n",
    "    # internal helper function to fetch data for a single company\n",
    "    def _get_salary_data_for_corp(corp_code):\n",
    "        endpoints = {\n",
    "            'individual': 'https://opendart.fss.or.kr/api/hmvAuditIndvdlBySttus.json',\n",
    "            'unregistered': 'https://opendart.fss.or.kr/api/unrstExctvMendngSttus.json',\n",
    "            'grouped': 'https://opendart.fss.or.kr/api/drctrAdtAllMendngSttusMendngPymntamtTyCl.json' \n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        # 1. individual executives (개인별 보수) source\n",
    "        for row in _get_json(endpoints['individual'], corp_code):\n",
    "            results.append({\n",
    "                'corp_code': corp_code,\n",
    "                'name': row.get('nm'),\n",
    "                'position': row.get('ofcps'),\n",
    "                'compensation': row.get('mendng_totamt'), \n",
    "                'salary_source': '개인별보수',\n",
    "                'salary_type': 'exact'\n",
    "            })\n",
    "\n",
    "        # 2. unregistered executives (미등기 임원) source\n",
    "        for row in _get_json(endpoints['unregistered'], corp_code):\n",
    "            results.append({\n",
    "                'corp_code': corp_code,\n",
    "                'name': '',\n",
    "                'position': row.get('se'),\n",
    "                'compensation': row.get('jan_salary_am'), \n",
    "                'salary_source': '미등기임원',\n",
    "                'salary_type': 'estimate'\n",
    "            })\n",
    "\n",
    "        # 3. grouped executives (임원 전체 보수 유형) source\n",
    "        for row in _get_json(endpoints['grouped'], corp_code):\n",
    "            results.append({\n",
    "                'corp_code': corp_code,\n",
    "                'name': '',\n",
    "                'position': row.get('se'),\n",
    "                'compensation': row.get('psn1_avrg_pymntamt'),\n",
    "                'salary_source': '임원전체보수유형',\n",
    "                'salary_type': 'estimate'\n",
    "            })\n",
    "            \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    # process all companies\n",
    "    all_salary_data = []\n",
    "\n",
    "    for corp_code in kospi_company_info_df['corp_code'].apply(lambda c: str(c).zfill(8)):\n",
    "        df = _get_salary_data_for_corp(corp_code)\n",
    "        \n",
    "        if not df.empty:\n",
    "            all_salary_data.append(df)\n",
    "\n",
    "        time.sleep(0.07)\n",
    "\n",
    "    # combine all individual df's into one\n",
    "    final_df = pd.concat(all_salary_data, ignore_index=True)\n",
    "    \n",
    "    # save file\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"salary_separate_{bsns_year}_{reprt_code}.csv\")\n",
    "    final_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"Salary data for {len(all_salary_data)} companies saved to: {output_path}\")\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd99ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_separate_df = get_salary_type(kospi_company_info_df, bsns_year, reprt_code, API_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945f624",
   "metadata": {},
   "source": [
    "#### 6. get_salary_total  \n",
    "\n",
    "for each corp, pulls the total combined salaries of all listed executives. \n",
    "\n",
    "[OPENDART | Guide for Developers to Remuneration for all directors and auditors](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00014)\n",
    "\n",
    "Required Keys:\n",
    "- crtfc_key (API key)\n",
    "- corp_code \n",
    "- bsns_year (fiscal year)\n",
    "- reprt_code \n",
    "\n",
    "The resulting **salary_total_df** keeps all response variables. This includes: \n",
    "- nmpr (total headcount of all directors and auditors)\n",
    "- mendng_totamt (total remuneration amount for all directors and auditors)\n",
    "- jan_avrg_mendng_am (the average remuneration per person)\n",
    "\n",
    "The total remuneration amount is then merged with **summary_df** as a *Total Compensation* column. The functions makes ~850 calls and executes in ~ 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary_total(kospi_company_info_df: pd.DataFrame, bsns_year: str, reprt_code: str, API_key: str, output_dir: str = BASE_DATA_DIR) -> pd.DataFrame:\n",
    "    url = \"https://opendart.fss.or.kr/api/hmvAuditAllSttus.json\"\n",
    "\n",
    "    def _get_json(url, corp_code):\n",
    "        params = {\n",
    "            'crtfc_key': API_key,\n",
    "            'corp_code': corp_code,\n",
    "            'bsns_year': bsns_year,\n",
    "            'reprt_code': reprt_code\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get('status') != '000' or 'list' not in data:\n",
    "                if data.get('status') != '000':\n",
    "                    print(f\"DART API Error for {corp_code}: {data.get('message')}\")\n",
    "                return []\n",
    "            return data['list']\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Request failed for {url} with params {params}: {e}\")\n",
    "            return []\n",
    "        \n",
    "    salary_total = []\n",
    "    \n",
    "    for corp_code in kospi_company_info_df['corp_code'].apply(lambda c: str(c).zfill(8)):\n",
    "        data_list = _get_json(url, corp_code)\n",
    "\n",
    "        if data_list:\n",
    "            df = pd.DataFrame(data_list)\n",
    "            salary_total.append(df)\n",
    "        \n",
    "        time.sleep(0.07)\n",
    "        \n",
    "    # concatenate all individual DataFrames into one\n",
    "    final_df = pd.concat(salary_total, ignore_index=True)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"salary_total_data_{bsns_year}_{reprt_code}.csv\")\n",
    "    final_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"Salary data for {len(salary_total)} companies saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76336d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DART API Error for 00600013: 조회된 데이타가 없습니다.\n",
      "DART API Error for 00435297: 조회된 데이타가 없습니다.\n",
      "DART API Error for 00907013: 조회된 데이타가 없습니다.\n",
      "DART API Error for 01880801: 조회된 데이타가 없습니다.\n",
      "DART API Error for 01885222: 조회된 데이타가 없습니다.\n",
      "DART API Error for 00182696: 조회된 데이타가 없습니다.\n",
      "Salary data for 844 companies saved to: data\\raw\\salary_total_data_2024_11011.csv\n"
     ]
    }
   ],
   "source": [
    "salary_total_df = get_salary_total(kospi_company_info_df, bsns_year, reprt_code, API_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f09ca0",
   "metadata": {},
   "source": [
    "#### 7. get_major_shareholder_data\n",
    "\n",
    "pulls the holding status of major shareholders. \n",
    "\n",
    "In the preprocessing notebook, shareholder status is merged with the exec data, such that if a registered or unregistered executive is listed as a major shareholder, their shares are appended to exec_df.\n",
    "\n",
    "[OPENDART | Guide for Developers to Information on largest shareholder](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00008)\n",
    "\n",
    "Required Keys:\n",
    "- crtfc_key (API key)\n",
    "- corp_code \n",
    "- bsns_year (fiscal year)\n",
    "- reprt_code \n",
    "\n",
    "The resulting **major_shareholder_df** contains all response keys for potential further evaluation. When merged to **exec_df**, only *trmend_posesn_stock_qota_rt* (shareholding ratio at the end of the reporting period) is added as a *shareholding_ratio* column. The following are not carried over: \n",
    "- bsis_posesn_stock_co\t(number of stocks at the beginning of the reporting period)\n",
    "- bsis_posesn_stock_qota_rt (shareholding ratio at the beginning of the reporting period)\n",
    "- trmend_posesn_stock_co (number of stocks at the end of the reporting period)\n",
    "\n",
    "Alternative Source: [OPENDART | Guide for Developers to Report of executives and major shareholders' ownership](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE004&apiId=AE00041) which pulls stock transaction updates by executives and major shareholders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271242e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_major_shareholder_data(api_key: str, kospi_codes_df: pd.DataFrame, bsns_year: int, reprt_code: str, output_dir: str = BASE_DATA_DIR) -> pd.DataFrame:\n",
    "    results = []\n",
    "    api_endpoint = \"https://opendart.fss.or.kr/api/hyslrSttus.json\"\n",
    "    total_corps = len(kospi_codes_df)\n",
    "\n",
    "    for idx, row in kospi_codes_df.iterrows():\n",
    "        corp_code = row['corp_code']\n",
    "        corp = str(corp_code).zfill(8)\n",
    "        corp_name = row['corp_name']\n",
    "\n",
    "        params = {\n",
    "            'crtfc_key': api_key,\n",
    "            'corp_code': corp,\n",
    "            'bsns_year': bsns_year,\n",
    "            'reprt_code': reprt_code\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(api_endpoint, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            if data['status'] == '000':\n",
    "                if 'list' in data and data['list']:\n",
    "                    df = pd.DataFrame(data['list'])\n",
    "                    results.append(df)\n",
    "            elif data['status'] == '013':\n",
    "                print(f\"No shareholder data available for {corp_name} ({corp_code}) for {bsns_year}/{reprt_code}.\")\n",
    "            else:\n",
    "                print(f\"API Error for {corp_name} ({corp_code}): Status {data.get('status')}, Message: {data.get('message')}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred for {corp_name} ({corp_code}): {e}\")\n",
    "\n",
    "        time.sleep(0.07)\n",
    "\n",
    "    if results:\n",
    "        shareholder_df = pd.concat(results, ignore_index=True)\n",
    "        output_filepath = os.path.join(output_dir, f'major_shareholders_{bsns_year}_{reprt_code}.csv')\n",
    "        save_df_to_csv(shareholder_df, output_filepath)\n",
    "        print(f\"\\nSuccessfully fetched and saved major shareholder data for {len(shareholder_df)} records.\")\n",
    "        return shareholder_df\n",
    "    else:\n",
    "        print(\"\\nNo major shareholder data was retrieved.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce067eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No shareholder data available for 미래에셋맵스 아시아퍼시픽 부동산공모 1호 투자회사 (00600013) for 2024/11011.\n",
      "No shareholder data available for 맥쿼리한국인프라투융자회사 (00435297) for 2024/11011.\n",
      "No shareholder data available for 한국투자ANKOR유전해외자원개발특별자산투자회사1호(지분증권) (00907013) for 2024/11011.\n",
      "No shareholder data available for 케이비발해인프라투융자회사 (01880801) for 2024/11011.\n",
      "No shareholder data available for 주식회사 대신밸류리츠위탁관리부동산투자회사 (01885222) for 2024/11011.\n",
      "No shareholder data available for 대한조선 주식회사 (00182696) for 2024/11011.\n",
      "DataFrame saved to data\\raw\\major_shareholders_2024_11011.csv\n",
      "\n",
      "Successfully fetched and saved major shareholder data for 9102 records.\n"
     ]
    }
   ],
   "source": [
    "major_shareholder_df = get_major_shareholder_data(API_key, kospi_company_info_df, bsns_year, reprt_code) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f16c5",
   "metadata": {},
   "source": [
    "### **Preprocessing**\n",
    "\n",
    "Filter and group data into two data dataframes: **exec_df** and **summary _df**. Unlike *data_extraction*, only the final cleaned and completed dfs will be saved to the processed data folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0fea6",
   "metadata": {},
   "source": [
    "#### 0. Build initial exec_df structure\n",
    "\n",
    "From the raw data file **executive_status_data_df**, the following cell drops the columns identified in *data extraction* (3.) get_executive_data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f674c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_df = executive_status_data_df.drop(\n",
    "    columns=['corp_cls', 'birth_ym', 'fte_at', 'tenure_end_on', 'stlm_dt'], \n",
    "    errors='ignore'\n",
    ").rename(\n",
    "    columns={\n",
    "        'rcept_no': 'disclosure',\n",
    "        'nm': 'name',\n",
    "        'sexdstn': 'gender',\n",
    "        'ofcps': 'position',\n",
    "        'rgist_exctv_at': 'exec_status',\n",
    "        'chrg_job': 'responsibilities',\n",
    "        'mxmm_shrholdr_relate': 'largest_shareholder_relate',\n",
    "        'hffc_pd': 'employment_period',\n",
    "        'trmend_posesn_stock_qota_rt': 'shareholding_ratio'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd801cc",
   "metadata": {},
   "source": [
    "#### **Building exec_df**\n",
    "#### 1. Parse Experience and Build Initial Structure\n",
    "\n",
    "separate_career passes in the prior_work column from **exec_df** to parse and categorize experience into education and work. The function prioritizes sorting work roles first, to avoid mislabeling education related positions. Job keywords only contain these related terms as the fallback defaults to work experience if the specific education keywords don't exist within each parsed string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32165a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_career(career_string):\n",
    "    if pd.isna(career_string):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    education = []\n",
    "    work_experience = []\n",
    "    \n",
    "    # prioritized keywords\n",
    "    job_keywords = ['교수', '총장', '강사', '연구원', '학장', '팀장', '실장', '감사', '대표', '회장', '이사']\n",
    "    edu_keywords = ['학사', '석사', '박사', '대학교', '법학', '대학원', '졸업', '수료', 'Univ.', 'School', 'College', 'MBA', 'U.', 'Institute', 'University']\n",
    "\n",
    "    career_items = career_string.split('\\n')\n",
    "    \n",
    "    for item in career_items:\n",
    "        # check for job keywords for education-related backgrounds to avoid sorting as education \n",
    "        if any(keyword in item for keyword in job_keywords):\n",
    "            work_experience.append(item.strip())\n",
    "        # if no job keywords, check for educational keywords\n",
    "        elif any(keyword in item for keyword in edu_keywords):\n",
    "            education.append(item.strip())\n",
    "        # default to work experience for other entries\n",
    "        else:\n",
    "            work_experience.append(item.strip())\n",
    "            \n",
    "    return (\n",
    "        education if education else np.nan,\n",
    "        work_experience if work_experience else np.nan\n",
    "    )\n",
    "exec_df[['education', 'work_exp']] = exec_df['main_career'].apply(\n",
    "    lambda x: pd.Series(separate_career(x))\n",
    ")\n",
    "\n",
    "# drop the old career column and reorder the columns \n",
    "exec_df = exec_df.drop(columns=['main_career']).pipe(\n",
    "    lambda df: df[['stock_code'] + [col for col in df.columns if col != 'stock_code']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc21f1",
   "metadata": {},
   "source": [
    "#### 2. Individual Audit Committee Membership\n",
    "\n",
    "The following code block extracts audit committee membership and auditor status from individual **exec_df** rows, preparing proper counts for **summary_df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71337c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_and_split(responsibility_string):\n",
    "    if not isinstance(responsibility_string, str):\n",
    "        return []\n",
    "    \n",
    "    # split the string by newlines, strip whitespace, and filter out empty strings\n",
    "    return [item.strip() for item in responsibility_string.split('\\n') if item.strip()]\n",
    "\n",
    "exec_df['responsibilities'] = exec_df['responsibilities'].apply(_clean_and_split)\n",
    "\n",
    "def is_audit_committee_member(responsibilities):\n",
    "    if not responsibilities:\n",
    "        return False\n",
    "    # check if any item in the list matches the audit committee pattern\n",
    "    for responsibility in responsibilities:\n",
    "        responsibility_cleaned = re.sub(r'\\s', '', responsibility)\n",
    "        if re.search(r'감사위원회위원|감사위원|감사위원장', responsibility_cleaned):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_auditor_exclusive(responsibilities):\n",
    "    if not responsibilities:\n",
    "        return False\n",
    "    # first, check if the person is an audit committee member and return False if they are\n",
    "    if is_audit_committee_member(responsibilities):\n",
    "        return False\n",
    "    \n",
    "    # otherwise, check for the isolated auditor pattern\n",
    "    for responsibility in responsibilities:\n",
    "        responsibility_cleaned = re.sub(r'\\s', '', responsibility)\n",
    "        if '감사' in responsibility_cleaned and not re.search(r'감사위원회위원|감사위원', responsibility_cleaned):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# apply the functions directly\n",
    "exec_df['is_audit_committee_member'] = exec_df['responsibilities'].apply(\n",
    "    lambda x: is_audit_committee_member(_clean_and_split(x))\n",
    ")\n",
    "\n",
    "exec_df['is_auditor'] = exec_df['responsibilities'].apply(\n",
    "    lambda x: is_auditor_exclusive(_clean_and_split(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990a58a6",
   "metadata": {},
   "source": [
    "#### 3. Assign Compensation\n",
    "\n",
    "assign_compensation appends the estimated/exact reported salary based on the executive's registered status and whether they serve on the audit committee. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c819288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_compensation(exec_df: pd.DataFrame, salary_type_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    exec_df['salary'] = None\n",
    "    exec_df['salary_source'] = None\n",
    "    exec_df['salary_type'] = None\n",
    "\n",
    "    for idx, row in exec_df.iterrows():\n",
    "        corp_code = row['corp_code']\n",
    "        name = row['name']\n",
    "        status = row.get('exec_status')\n",
    "        is_auditor = row.get('is_auditor', False)\n",
    "        is_committee = row.get('is_audit_committee_member', False)\n",
    "\n",
    "        # match by same name and corp for those whose exact salary was listed\n",
    "        match = salary_separate_df[\n",
    "            (salary_separate_df['corp_code'] == corp_code) & \n",
    "            (salary_separate_df['name'] == name)\n",
    "        ]\n",
    "\n",
    "        if not match.empty:\n",
    "            row_data = match.iloc[0]\n",
    "\n",
    "        # for those whose name was not explicitly listed, assign them to the estimates based on their role \n",
    "        else:\n",
    "            if status == '미등기':\n",
    "                label = '미등기임원' \n",
    "            elif is_auditor:\n",
    "                label = '감사'\n",
    "            elif status == '사외이사':\n",
    "                label = '감사위원회 위원' if is_committee else '사외이사(감사위원회 위원 제외)'\n",
    "            else:\n",
    "                label = '등기이사(사외이사, 감사위원회 위원 제외)'\n",
    "\n",
    "            group_match = salary_separate_df[\n",
    "                (salary_separate_df['corp_code'] == corp_code) & \n",
    "                (salary_separate_df['name'].isna()) & \n",
    "                (salary_separate_df['position'] == label)\n",
    "            ]\n",
    "\n",
    "            row_data = group_match.iloc[0] if not group_match.empty else pd.Series(dtype='object')\n",
    "\n",
    "        # match assigned roles to salaries\n",
    "        if not row_data.empty:\n",
    "            exec_df.at[idx, 'salary'] = row_data.get('compensation')\n",
    "            exec_df.at[idx, 'salary_source'] = row_data.get('salary_source')\n",
    "            exec_df.at[idx, 'salary_type'] = row_data.get('salary_type')\n",
    "\n",
    "    return exec_df\n",
    "\n",
    "exec_df = assign_compensation(exec_df, salary_separate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c76624",
   "metadata": {},
   "source": [
    "#### 4. Merge Shareholder Data\n",
    "\n",
    "merges **exec_df** with **major_shareholder_df** to shareholding ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d5b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_df = pd.merge(exec_df, major_shareholder_df[['corp_code', 'nm', 'trmend_posesn_stock_qota_rt']], \n",
    "                   left_on=['corp_code', 'name'], right_on=['corp_code', 'nm'], how='left')\n",
    "exec_df = exec_df.drop(columns=['nm']).rename(\n",
    "    columns={'trmend_posesn_stock_qota_rt': 'shareholding_ratio'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c2645",
   "metadata": {},
   "source": [
    "#### 5. Standardize Tenure\n",
    "\n",
    "converts the tenure column into strictly month format. The updated *employment_period* column of **exec_df** will reflect the total number of months worked within the listed corporation, up to the reference data defined at the top of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tenure_to_months(tenure_str, current_date=None):\n",
    "    if pd.isna(tenure_str) or not isinstance(tenure_str, str) or not tenure_str.strip():\n",
    "        return pd.NA\n",
    "        \n",
    "    tenure_str = tenure_str.strip()\n",
    "    \n",
    "    # 1. all date formats, including those with extra text\n",
    "    date_match = re.search(r'(\\d{2,4}[년\\.\\s]\\d{1,2}[월]?(?:[년\\.\\s]\\d{1,2}[일])?|\\d{1,2}\\.\\d{1,2}\\.\\d{1,2})', tenure_str)\n",
    "    \n",
    "    if date_match:\n",
    "        date_str = date_match.group(1).replace(' ', '').replace('년', '.').replace('월', '').replace('일', '')\n",
    "        date_obj = pd.NaT\n",
    "        \n",
    "        # parse the cleaned date string with multiple formats\n",
    "        date_formats = ['%Y.%m.%d', '%Y.%m', '%d.%m.%y', '%y.%m.%d', '%y.%m']\n",
    "        for fmt in date_formats:\n",
    "            try:\n",
    "                date_obj = pd.to_datetime(date_str, format=fmt, errors='raise')\n",
    "                break # Exit the loop if parsing is successful\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "    \n",
    "        if pd.notna(date_obj):\n",
    "            if current_date is None:\n",
    "                current_date = datetime.now()\n",
    "            \n",
    "            total_months = (current_date.year - date_obj.year) * 12 + (current_date.month - date_obj.month)\n",
    "            return float(max(0, total_months))\n",
    "    \n",
    "    # 2. decimal years (e.g., '11.3년', '22.5')\n",
    "    match_deci = re.search(r'^(\\d+(?:\\.\\d+)?)(?:년)?$', tenure_str)\n",
    "    if match_deci:\n",
    "        decimal_years = float(match_deci.group(1))\n",
    "        return decimal_years * 12\n",
    "    \n",
    "    # 3. years and months (e.g., \"3년 6개월\", \"4년4개월\")\n",
    "    match_ym = re.search(r'(\\d+)\\s*년(?:[^\\d]+)?\\s*(\\d+)\\s*개월', tenure_str)\n",
    "    if match_ym:\n",
    "        years = int(match_ym.group(1))\n",
    "        months = int(match_ym.group(2))\n",
    "        return float(years * 12 + months)\n",
    "        \n",
    "    # 4. years only (e.g., \"3년\")\n",
    "    match_y = re.search(r'^(\\d+)\\s*년$', tenure_str)\n",
    "    if match_y:\n",
    "        years = int(match_y.group(1))\n",
    "        return float(years * 12)\n",
    "        \n",
    "    # 5. months only (e.g., \"18개월\")\n",
    "    match_m = re.search(r'^(\\d+)\\s*개월$', tenure_str)\n",
    "    if match_m:\n",
    "        months = int(match_m.group(1))\n",
    "        return float(months)\n",
    "    \n",
    "    return pd.NA\n",
    "\n",
    "exec_df['employment_period'] = exec_df['employment_period'].apply(\n",
    "    lambda x: convert_tenure_to_months(x, current_date=reference_date) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60faa94",
   "metadata": {},
   "source": [
    "#### **Building summary_df**\n",
    "\n",
    "#### 1. Initial summary_df\n",
    "\n",
    "groups and summarizes **exec_df** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary(group): # group and sum the relevant data \n",
    "    voting_directors_group = group[~group['exec_status'].isin(['미등기', '감사'])]\n",
    "    female_voting = (voting_directors_group['gender'] == '여').sum()\n",
    "    male_voting = (voting_directors_group['gender'] == '남').sum()\n",
    "\n",
    "    return pd.Series({\n",
    "        'audit_committee': group['is_audit_committee_member'].sum(),\n",
    "        'audit_committee_ods': ((group['is_audit_committee_member']) & (group['exec_status'] == '사외이사')).sum(),\n",
    "        'inside_directors': group['exec_status'].isin(['사내이사', '대표집행임원']).sum(),\n",
    "        'outside_directors': (group['exec_status'] == '사외이사').sum(),\n",
    "        'female_voting': female_voting,\n",
    "        'male_voting': male_voting,\n",
    "        'voting_directors': female_voting + male_voting,\n",
    "        'other_non_exec_directors': (group['exec_status'] == '기타비상무이사').sum(),\n",
    "        'auditors': group['is_auditor'].sum(),\n",
    "        'non_registered': (group['exec_status'] == '미등기').sum()\n",
    "    })\n",
    "\n",
    "summary_df = exec_df.groupby(['stock_code', 'corp_code', 'corp_name'], as_index=False).apply( # reindex \n",
    "    extract_summary, include_groups=False\n",
    ")\n",
    "\n",
    "# merge saved assets data\n",
    "summary_df = pd.merge( \n",
    "    summary_df,\n",
    "    assets_df[['corp_code', '2024_total_assets', '2023_total_assets', '2022_total_assets']],\n",
    "    on='corp_code',\n",
    "    how='left'\n",
    ")\n",
    "# if there were multiple disclosures reported for one corp, append the most recent one \n",
    "disclosure = exec_df.groupby('corp_code')['disclosure'].max().reset_index() \n",
    "summary_df = pd.merge(\n",
    "    summary_df,\n",
    "    disclosure,\n",
    "    on='corp_code',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "salary_total_df = pd.merge(\n",
    "    summary_df, \n",
    "    salary_total_df['corp_code', 'mendng_totamt'],\n",
    "    on='corp_code', \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752861ef",
   "metadata": {},
   "source": [
    "#### 2. Audit Committee Checks\n",
    "\n",
    "For **summary_df**, each corp goes through two rounds of governance checks (*audit_committee_compliance*). To verify that the companies flagged in the first check are due to actual discrepencies and not incomplete data pulled from OPENDART's executive status API, we will parse the flagged company's disclosure report, correct missing data, and run through the check again. \n",
    "\n",
    "To access the audit committee disclosures directly, **missing_acm_urls(flagged_df)** will pull the relevant url from opendart reader's subdocs function. The direct link to the audit committee portion will then be parsed through in the **parse_and_update_audit_members(audit_targets_df, exec_df, summary_df)** function. If the **summary_df** data on audit committee size and membership doesn't match what's listed on the disclosure report directly, the function will update **summary_df**. \n",
    "\n",
    "On the second pass, corps that still fail the committee check will be flagged, alongside their failed condition. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd359c95",
   "metadata": {},
   "source": [
    "##### 2A. check_governance_compliance\n",
    "\n",
    "runs checks on **summary_df** for the following:\n",
    "\n",
    "1. Mandated Audit Committee: If a corporation's total assets > 2T KRW, an audit committee must exist with at least 3 members. As corporations have a 2 year grace period, the function passes in the total asset value from 2 years prior. \n",
    "2. Outside Majority: If a mandated audit committee exists, outside directors must make up a majority of the acting members. \n",
    "3. Outside Voting: Outside Directors must make up at least 1/4 of the total Voting Directors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9545e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_audit_committee(df):\n",
    "    flagged = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        corp_code = row['corp_code']\n",
    "\n",
    "        # get total assets from 2 years prior\n",
    "        row_total_assets = row['2022_total_assets']\n",
    "\n",
    "        num_audit_committee = row['audit_committee']\n",
    "        num_outside_directors = row['outside_directors']  \n",
    "        num_voting_directors = row['voting_directors']\n",
    "        num_outside_committee = row['audit_committee_ods']\n",
    "\n",
    "        failures = []\n",
    "\n",
    "        # only check for companies with assets above threshold\n",
    "        if pd.notna(row_total_assets) and row_total_assets > 2_000_000_000_000:\n",
    "            if pd.isna(num_audit_committee) or num_audit_committee == 0:\n",
    "                failures.append(\"No Audit Committee listed\")\n",
    "            elif num_audit_committee < 3:\n",
    "                failures.append(f\"Audit Committee has fewer than 3 members ({num_audit_committee})\")\n",
    "\n",
    "            if pd.notna(num_audit_committee) and num_audit_committee > 0:\n",
    "                if pd.isna(num_outside_committee):\n",
    "                    failures.append(\"Missing count of Audit Committee Outside Directors.\")\n",
    "                elif num_outside_committee < (2/3) * num_audit_committee:\n",
    "                    failures.append(f\"Audit Committee Outside Directors ({num_outside_committee}) < 2/3 of Audit Committee ({num_audit_committee})\")\n",
    "\n",
    "            if pd.notna(num_outside_directors) and pd.notna(num_voting_directors) and num_voting_directors > 0:\n",
    "                if num_outside_directors < (1/4) * num_voting_directors:\n",
    "                    failures.append(f\"Outside Directors ({num_outside_directors}) < 1/4 of Voting Directors ({num_voting_directors})\")\n",
    "\n",
    "        if failures:\n",
    "            flagged.append({'corp_code': corp_code, 'flagged_conditions': \"; \".join(failures)})\n",
    "\n",
    "    failed_df = pd.DataFrame(flagged)\n",
    "    return pd.merge(failed_df, df, on='corp_code', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0d4aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged = check_audit_committee(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b0a83",
   "metadata": {},
   "source": [
    "##### 2B. missing_acm_urls\n",
    "\n",
    "for the flagged companies, save the url to their audit committee disclosure page to verify committee status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7a7e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_acm_urls(flagged_df):\n",
    "    results = []\n",
    "\n",
    "    for idx, row in flagged_df.iterrows():\n",
    "        company = row['corp_name']\n",
    "        corp = row['corp_code']\n",
    "        rcp = row['disclosure'] \n",
    "\n",
    "        try:\n",
    "            subdocs = dart.sub_docs(str(rcp))  # pass in disclosure code to dart function\n",
    "            match = subdocs[subdocs['title'].str.contains(\"감사제도에 관한 사항\")] # find the document detailing audit committee status\n",
    "\n",
    "            if not match.empty:\n",
    "                url = match.iloc[0]['url']\n",
    "            else:\n",
    "                url = None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch for {corp} ({rcp}): {e}\")\n",
    "            url = None\n",
    "\n",
    "        results.append({\n",
    "            'corp_code': str(corp),\n",
    "            'corp_name': company,\n",
    "            'rcept_no': rcp,\n",
    "            'url': url,\n",
    "        })\n",
    "        \n",
    "        time.sleep(0.7)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_targets_df = missing_acm_urls(flagged).drop_duplicates(subset=['corp_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83938e67",
   "metadata": {},
   "source": [
    "##### 2C. parse_and_update_audit_members \n",
    "\n",
    "parses through each flagged company's audit committee disclosures for a table listing audit committee members. If it fails to find one based on the title and table format, it will make 0 changes to **summary_df**. If it does find a list of audit committee members, it will update **summary_df** with the size of the committee and the number of outside directors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_update_audit_members(audit_targets_df, exec_df, summary_df):\n",
    "    for df in [exec_df, summary_df]:\n",
    "        if 'corp_code' in df.columns:\n",
    "            df['corp_code'] = df['corp_code'].astype(str)\n",
    "    \n",
    "    new_execs_to_add = []\n",
    "    summary_updates = {}\n",
    "\n",
    "    for idx, row in audit_targets_df.iterrows():\n",
    "        corp_code = str(row['corp_code'])\n",
    "        company = row['corp_name']\n",
    "        url = row['url']\n",
    "\n",
    "        if pd.isna(url) or not isinstance(url, str):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, timeout=20)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            members_found = []\n",
    "            auditors_found = []\n",
    "            \n",
    "            # find the table under a specific committee title\n",
    "            # search for a header containing any variation of '감사위원 현황' or '감사위원회 위원의 인적사항' \n",
    "            ac_header_patterns = [\n",
    "                re.compile(r'감사위원\\s*현황'),\n",
    "                re.compile(r'감사위원회\\s*위원의\\s*인적사항'),\n",
    "                re.compile(r'감사위원회\\s*위원'),\n",
    "                re.compile(r'감사기구\\s*관련\\s*사항')\n",
    "            ]\n",
    "            \n",
    "            found_ac_section = None\n",
    "            ac_table = None\n",
    "            for pattern in ac_header_patterns:\n",
    "                found_ac_section = soup.find(string=pattern)\n",
    "                if found_ac_section:\n",
    "                    # find the first table that comes after this specific header\n",
    "                    ac_table = found_ac_section.find_next('table')\n",
    "                    if ac_table:\n",
    "                        break\n",
    "            \n",
    "            if ac_table:\n",
    "                # table parsing logic to extract listed name and outside director classification \n",
    "                headers = [th.get_text(strip=True).replace('\\xa0', '').replace('\\n', '') for tr in ac_table.find_all('tr', limit=2) for th in tr.find_all(['th', 'td'])]\n",
    "                name_idx = next((i for i, h in enumerate(headers) if '성명' in h), None)\n",
    "                outside_idx = next((i for i, h in enumerate(headers) if '사외이사' in h), None)\n",
    "                \n",
    "                if name_idx is not None and outside_idx is not None:\n",
    "                    # prioritize tbody for finding data rows\n",
    "                    data_rows = ac_table.find_all('tbody')[0].find_all('tr') if ac_table.find('tbody') else ac_table.find_all('tr')[len(ac_table.find_all('tr', limit=2)):]\n",
    "                    for tr in data_rows:\n",
    "                        tds = tr.find_all(['td', 'th'])\n",
    "                        if len(tds) > max(name_idx, outside_idx):\n",
    "                            name = tds[name_idx].get_text(strip=True)\n",
    "                            is_outside = tds[outside_idx].get_text(strip=True)\n",
    "                            if name and name != '-' and '---' not in name:\n",
    "                                is_outside_flag = '예' in is_outside or 'O' in is_outside\n",
    "                                members_found.append({'name': name, 'is_outside': is_outside_flag})\n",
    "      \n",
    "                                        \n",
    "            # update if table found with audit committee members \n",
    "            if members_found:\n",
    "                total_members = len(members_found)\n",
    "                outside_members = sum(1 for member in members_found if member['is_outside'])\n",
    "                \n",
    "                for member in members_found:\n",
    "                    name = member['name']\n",
    "                    existing_mask = (exec_df['corp_code'] == corp_code) & (exec_df['name'] == name)\n",
    "                    if not exec_df[existing_mask].empty:\n",
    "                        exec_df.loc[existing_mask, 'is_audit_committee_member'] = True\n",
    "                    else:\n",
    "                        new_execs_to_add.append({\n",
    "                            'corp_code': corp_code, 'corp_name': company, 'name': name,\n",
    "                            'chrg_job': '감사위원회 위원', 'is_audit_committee_member': True\n",
    "                        })\n",
    "                \n",
    "                summary_updates[corp_code] = {\n",
    "                    'audit_committee': total_members, 'audit_committee_ods': outside_members,\n",
    "                }\n",
    "            else:\n",
    "                summary_updates[corp_code] = {\n",
    "                    'audit_committee': 0, 'audit_committee_ods': 0,\n",
    "                }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred for {corp_code} - {company}: {e}\")\n",
    "        time.sleep(0.7)\n",
    "    \n",
    "    for corp_code, update in summary_updates.items():\n",
    "        summary_df.loc[summary_df['corp_code'] == corp_code, 'audit_committee'] = update['audit_committee']\n",
    "        summary_df.loc[summary_df['corp_code'] == corp_code, 'audit_committee_ods'] = update['audit_committee_ods']\n",
    "        \n",
    "    return exec_df, summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca57f32",
   "metadata": {},
   "source": [
    "Run the check again, now with the updated information. The remaining flags will be printed alongside their condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46471b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Parsed 삼양홀딩스 — 5 members found.\n",
      "[OK] Parsed 하이트진로 — 4 members found.\n",
      "[OK] Parsed 유한양행 — 4 members found.\n",
      "[NO COLUMNS] Could not find '성명' or '사외이사' columns for CJ대한통운\n",
      "[OK] Parsed 하이트진로홀딩스 — 4 members found.\n",
      "[NO TABLE] Header found but no table nearby for 두산\n",
      "[OK] Parsed DL — 4 members found.\n",
      "[OK] Parsed 한국앤컴퍼니 — 5 members found.\n",
      "[OK] Parsed 기아 — 5 members found.\n",
      "[OK] Parsed 한화손해보험 — 4 members found.\n",
      "[OK] Parsed 롯데손해보험 — 4 members found.\n",
      "[OK] Parsed 흥국화재 — 4 members found.\n",
      "[NO TABLE] Header found but no table nearby for SK하이닉스\n",
      "[OK] Parsed 영풍 — 4 members found.\n",
      "[OK] Parsed 현대건설 — 5 members found.\n",
      "[OK] Parsed 삼성화재해상보험 — 4 members found.\n",
      "[OK] Parsed 한화 — 4 members found.\n",
      "[OK] Parsed DB하이텍 — 5 members found.\n",
      "[OK] Parsed CJ — 4 members found.\n",
      "[NO COLUMNS] Could not find '성명' or '사외이사' columns for LX인터내셔널\n",
      "[OK] Parsed 유진증권 — 4 members found.\n",
      "[NO HEADER] Could not find audit committee header for 동국홀딩스\n",
      "[NO HEADER] Could not find audit committee header for KG케미칼\n",
      "[OK] Parsed 세아베스틸지주 — 5 members found.\n",
      "[OK] Parsed 현대해상 — 4 members found.\n",
      "[NO TABLE] Header found but no table nearby for 현대차증권\n",
      "[OK] Parsed SK증권 — 4 members found.\n",
      "[OK] Parsed 대상 — 5 members found.\n",
      "[OK] Parsed 신영증권 — 4 members found.\n",
      "[NO TABLE] Header found but no table nearby for SK네트웍스\n",
      "[OK] Parsed 오리온홀딩스 — 4 members found.\n",
      "[NO HEADER] Could not find audit committee header for 코오롱\n",
      "[NO HEADER] Could not find audit committee header for 아세아\n",
      "[OK] Parsed 고려제강 — 4 members found.\n",
      "[OK] Parsed 한진 — 4 members found.\n",
      "[OK] Parsed 넥센타이어 — 5 members found.\n",
      "[OK] Parsed 케이씨씨 — 4 members found.\n",
      "[OK] Parsed 아모레퍼시픽홀딩스 — 4 members found.\n",
      "[NO HEADER] Could not find audit committee header for 세아제강지주\n",
      "[OK] Parsed 코오롱글로벌 — 4 members found.\n",
      "[NO TABLE] Header found but no table nearby for 대웅\n",
      "[NO TABLE] Header found but no table nearby for 태광산업\n",
      "[NO HEADER] Could not find audit committee header for 한일홀딩스\n",
      "[NO TABLE] Header found but no table nearby for 유안타증권\n",
      "[OK] Parsed 대한항공 — 5 members found.\n",
      "[OK] Parsed 한화투자증권 — 4 members found.\n",
      "[OK] Parsed 대신증권 — 4 members found.\n",
      "[OK] Parsed LG — 5 members found.\n",
      "[NO TABLE] Header found but no table nearby for KG모빌리티\n",
      "[NO TABLE] Header found but no table nearby for 포스코퓨처엠\n",
      "[NO TABLE] Header found but no table nearby for 코리안리\n",
      "[OK] Parsed 롯데정밀화학 — 5 members found.\n",
      "[OK] Parsed 현대제철 — 5 members found.\n",
      "[OK] Parsed 신세계 — 4 members found.\n",
      "[OK] Parsed 농심 — 5 members found.\n",
      "[OK] Parsed 삼천리 — 4 members found.\n",
      "[OK] Parsed 효성 — 4 members found.\n",
      "[NO TABLE] Header found but no table nearby for 한신공영\n",
      "[NO TABLE] Header found but no table nearby for 롯데지주\n",
      "[NO HEADER] Could not find audit committee header for SGC에너지\n",
      "[NO HEADER] Could not find audit committee header for 녹십자홀딩스\n",
      "[OK] Parsed 롯데칠성음료 — 6 members found.\n",
      "[OK] Parsed 현대자동차 — 6 members found.\n",
      "[NO TABLE] Header found but no table nearby for 현대지에프홀딩스\n",
      "[OK] Parsed POSCO홀딩스 — 4 members found.\n",
      "[OK] Parsed 넥센 — 4 members found.\n",
      "[OK] Parsed DB손해보험 — 4 members found.\n",
      "[NO TABLE] Header found but no table nearby for 에스엘\n",
      "[OK] Parsed 대한해운 — 4 members found.\n",
      "[NO DATA] Table for 삼성전자 is empty or malformed\n",
      "[NO TABLE] Header found but no table nearby for NH투자증권\n",
      "[OK] Parsed 동원산업 — 4 members found.\n",
      "[OK] Parsed SK디스커버리 — 5 members found.\n",
      "[OK] Parsed 제주은행 — 4 members found.\n",
      "[NO COLUMNS] Could not find '성명' or '사외이사' columns for LS\n",
      "[NO DATA] Table for 녹십자 is empty or malformed\n",
      "[OK] Parsed GS건설 — 4 members found.\n",
      "[OK] Parsed 삼성SDI — 4 members found.\n",
      "[NO TABLE] Header found but no table nearby for 대한유화\n",
      "[OK] Parsed 미래에셋증권 — 4 members found.\n",
      "[OK] Parsed AK홀딩스 — 5 members found.\n",
      "[NO DATA] Table for GS리테일 is empty or malformed\n",
      "[NO DATA] Table for 오뚜기 is empty or malformed\n",
      "[NO HEADER] Could not find audit committee header for DN오토모티브\n",
      "[OK] Parsed F&F 홀딩스 — 4 members found.\n",
      "[OK] Parsed 서연 — 4 members found.\n",
      "[NO TABLE] Header found but no table nearby for 호텔신라\n",
      "[NO TABLE] Header found but no table nearby for 삼성전기\n",
      "[NO TABLE] Header found but no table nearby for 무림페이퍼\n",
      "[NO TABLE] Header found but no table nearby for 태영건설\n",
      "[NO TABLE] Header found but no table nearby for HD한국조선해양\n",
      "[OK] Parsed 한화솔루션 — 4 members found.\n",
      "[NO HEADER] Could not find audit committee header for 영원무역홀딩스\n",
      "[NO TABLE] Header found but no table nearby for OCI홀딩스\n",
      "[OK] Parsed 엘에스일렉트릭 — 6 members found.\n",
      "[OK] Parsed 고려아연 — 4 members found.\n",
      "[OK] Parsed 삼성중공업 — 4 members found.\n",
      "[OK] Parsed HD현대미포 — 4 members found.\n",
      "Exception occurred for 00115977 - 아이에스동서: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00138279 - S-Oil: ('Connection aborted.', ConnectionAbortedError(10053, 'An established connection was aborted by the software in your host machine', None, 10053, None))\n",
      "Exception occurred for 00105961 - LG이노텍: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00165413 - 롯데케미칼: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00164645 - HMM: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00106623 - 현대위아: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00106368 - 금호석유화학: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00139889 - SKC: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00164788 - 현대모비스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00126566 - 한화에어로스페이스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00164636 - HDC: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00158501 - 에스원: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00102432 - 계룡건설산업: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00159193 - 한국전력공사: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00104856 - 삼성증권: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00115676 - KG스틸: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00161976 - 한세예스24홀딩스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00115694 - DB증권: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00159023 - SK텔레콤: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00164724 - 현대엘리베이터: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00155355 - 풀무원: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00165583 - E1: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00126186 - 삼성에스디에스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00144164 - SK가스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00161125 - 한온시스템: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00113997 - 롯데에너지머티리얼즈: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00138792 - 아시아나항공: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00170558 - 코웨이: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00120526 - 롯데쇼핑: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00176914 - 다우기술: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00149646 - 기업은행: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00126308 - 삼성E&A: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00149655 - 삼성물산: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00122737 - 팬오션: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00126292 - 삼성카드: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00148276 - 제일기획: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00190321 - 케이티: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00156859 - 다올투자증권: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00113359 - 교보증권: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00231363 - LG유플러스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00126256 - 삼성생명: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00244455 - 케이티앤지: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00159616 - 두산에너빌리티: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00105873 - LG디스플레이: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00171265 - 파라다이스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00158316 - NICE: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00181712 - SK: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00255619 - 강원랜드: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00266961 - NAVER: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00258801 - 카카오: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00203315 - 콘텐트리중앙: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00261285 - 한국가스공사: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00225159 - SNT홀딩스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00261443 - 엔씨소프트: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00296290 - 키움증권: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00111704 - 한화오션: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00344287 - HD현대인프라코어: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00124540 - 대우건설: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00124504 - 포스코인터내셔널: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00309503 - 한국항공우주: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00356370 - LG생활건강: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00356361 - LG화학: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00382199 - 신한지주: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00412597 - 현대홈쇼핑: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00377610 - 세아홀딩스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00299002 - HL홀딩스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00302926 - 현대로템: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00139834 - LG씨엔에스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00401731 - LG전자: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00398701 - 엘앤에프: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00413046 - 셀트리온: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00428251 - 현대백화점: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00432102 - 한국금융지주: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00159698 - 지역난방공사: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00158307 - 롯데하이마트: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00481454 - 금호타이어: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00500254 - GS: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00303873 - CJ CGV: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00503668 - LIG넥스원: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00195229 - 미스토홀딩스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00117267 - 동양생명: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00539274 - 대상홀딩스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00112332 - 미래에셋생명: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00360595 - 현대글로비스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00547583 - 하나금융지주: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00113058 - 한화생명: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00545716 - 롯데렌탈: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00583424 - 아모레퍼시픽: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00593032 - LF: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00631518 - SK이노베이션: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00633835 - HJ중공업: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00635134 - CJ제일제당: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00684714 - 풍산: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00688996 - KB금융: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00759513 - LX하우시스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00776820 - 영원무역: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00795135 - 코오롱인더: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00854997 - 에스디바이오센서: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00860332 - 메리츠금융지주: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00858364 - BNK금융지주: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00878915 - iM금융지주: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00872984 - 이마트: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00896285 - 삼양사: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00937324 - 한국타이어앤테크놀로지: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00939331 - 한국콜마: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00980122 - JB금융지주: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00983040 - 한진칼: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00983271 - NHN: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00990165 - 아세아시멘트: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01042775 - HL만도: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00877059 - 삼성바이오로직스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00508344 - SK디앤디: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01060744 - 한솔제지: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00565154 - 이노션: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00904672 - 넷마블: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00760971 - 크래프톤: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01205709 - HD현대: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01205851 - HD현대일렉트릭: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01205842 - HD현대건설기계: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01238169 - 오리온: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00339391 - 한화시스템: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01258507 - 롯데웰푸드: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01263022 - BGF리테일: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01267170 - SK케미칼: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01310269 - HDC현대산업개발: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01316236 - 효성화학: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01316227 - 효성티앤씨: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01316245 - 효성중공업: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01316254 - HS효성첨단소재: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01319808 - 한일시멘트: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01319899 - SK바이오사이언스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 00362441 - 현대오토에버: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01350869 - 우리금융지주: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01133217 - 카카오뱅크: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01390344 - HD현대중공업: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01363818 - 롯데리츠: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01428203 - 케이씨씨글라스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01415892 - 제이알글로벌리츠: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01204056 - 하이브: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01386916 - SK아이이테크놀로지: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01497869 - 티와이홀딩스: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01437186 - ESR켄달스퀘어리츠: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01515323 - LG에너지솔루션: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01524093 - DL이앤씨: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01244601 - 카카오페이: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01535150 - SK리츠: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01596425 - SK스퀘어: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Exception occurred for 01765265 - 동국제강: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    }
   ],
   "source": [
    "exec_df, summary_df = parse_and_update_audit_members(\n",
    "    audit_targets_df,\n",
    "    exec_df,\n",
    "    summary_df\n",
    ") # the resulting exec_df and summary_df will be updated from the parsed audit committee disclosure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_flags = check_audit_committee(summary_df)\n",
    "\n",
    "print(\"--- Governance Compliance Check Results ---\")\n",
    "\n",
    "# print corporations with a single auditor (no audit committee)\n",
    "no_ac_but_auditor = updated_flags[(updated_flags['audit_committee'] == 0) & (updated_flags['auditors'] > 0)]\n",
    "if not no_ac_but_auditor.empty:\n",
    "    print(\"\\nCorporations with a single auditor (no audit committee):\")\n",
    "    for index, row in no_ac_but_auditor.iterrows():\n",
    "        print(f\"  - {row['corp_name']} (Auditor: {row['auditors']})\")\n",
    "else:\n",
    "    print(\"\\nNo corporations found with a single auditor (no audit committee).\")\n",
    "\n",
    "# print corporations with a partial audit committee (< 3 members)\n",
    "partial_ac = updated_flags[((updated_flags['audit_committee'] > 0) & (updated_flags['audit_committee'] < 3))]\n",
    "if not partial_ac.empty:\n",
    "    print(\"\\nCorporations with a partial audit committee (< 3 members):\")\n",
    "    for index, row in partial_ac.iterrows():\n",
    "        print(f\"  - {row['corp_name']} (Members: {row['audit_committee']})\")\n",
    "else:\n",
    "    print(\"\\nNo corporations found with a partial audit committee.\")\n",
    "\n",
    "# print corporations with no audit committee or auditor found\n",
    "no_ac_no_auditor = updated_flags[(updated_flags['audit_committee'] == 0) & (updated_flags['auditors'] == 0)]\n",
    "if not no_ac_no_auditor.empty:\n",
    "    print(\"\\nCorporations with no audit committee or auditor found:\")\n",
    "    for index, row in no_ac_no_auditor.iterrows():\n",
    "        print(f\"  - {row['corp_name']}\")\n",
    "else:\n",
    "    print(\"\\nNo corporations found with neither an audit committee nor an auditor.\")\n",
    "\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9409d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join('..', 'data', 'processed')\n",
    "exec_file_path = os.path.join(output_folder, 'exec_df.csv')\n",
    "summary_file_path = os.path.join(output_folder, 'summary_df.csv')\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "exec_df.to_csv(exec_file_path, index=False, encoding='utf-8-sig')\n",
    "summary_df.to_csv(summary_file_path, index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
