{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00a8b05",
   "metadata": {},
   "source": [
    "# **Governance Database Extraction and Preprocessing**\n",
    "\n",
    "Governance Database Proj retrieves data directly from OPENDART to build a database of KOSPI-listed corporations and executive status available through posted disclosures. \n",
    "\n",
    "For stability, information is pulled directly from OPENDART API where possible. Almost all OPENDART calls require a single API call per corporation or report request, which is reflected in the total execution time. Only one function relies on OpenDartReader (to search for direct links to audit committee information used for governance check). [OPENDART API limits](https://engopendart.fss.or.kr/cop/bbs/selectArticleDetail.do) are as follows: \n",
    "- Individual: 20,000 calls a day (the limit is for all 83 API services and not by service)\n",
    "- Corporation (business registration and registered IP)\n",
    "    - 2 services (\"Search disclosures\" and \"Overview of corporate status\"): Unlimited\n",
    "    - 81 services (excluding \"Search disclosures\" and \"Overview of corporate status\"): 20,000 calls a day (the limit is for all 81 API services and not by service)\n",
    "- 1,000 calls per minute\n",
    "\n",
    "### Environment Set Up \n",
    "Runs on Python 3.13.5. The cell below will check that the current kernel is using the correct Python version and raise an error otherwise. To set a virtual environment, execute the following lines in the terminal: \n",
    "\n",
    "    python3.13.5 -m venv virtualenv\n",
    "\n",
    "    virtualenv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23a744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 13, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca9e5e",
   "metadata": {},
   "source": [
    "### Outputs\n",
    "\n",
    "By the end of the project, the following two databases will be produced: \n",
    "1. **executive_df**, providing details on the 15k+ listed executives, including information such as registered officer status, shareholder relations, salary, and professional experience.\n",
    "\n",
    "2. **summary_df**,  a grouped dataset across corp-level information, including number of directory types, audit committee size, and total assets from the past three years (used to determine audit committee mandate).\n",
    "\n",
    "*navigate to README.md file for reference*\n",
    "\n",
    "<br> \n",
    "The cell below checks for the necessary folders. If it returns False, create a folder (at the same directory level as notebooks, not within) labeled 'data' and within it, two subfolders: 'raw' and 'processed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f04f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = os.path.join(r'..\\..', 'data')\n",
    "raw_dir = os.path.join(data_dir, 'raw')\n",
    "processed_dir = os.path.join(data_dir, 'processed')\n",
    "\n",
    "print(os.path.isdir(raw_dir) and os.path.isdir(processed_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6701c639",
   "metadata": {},
   "source": [
    "### Packages \n",
    "\n",
    "Update **API_key**, **bsns_year**, and **reprt_code** as needed.\n",
    "\n",
    "OPENDART reprt_code: \n",
    "- First Quarterly Report : 11013\n",
    "- Semi-annual Report : 11012\n",
    "- Third Quarterly Report : 11014\n",
    "- Annual Report : 11011\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "21b620bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import zipfile \n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "from concurrent.futures import ThreadPoolExecutor \n",
    "\n",
    "import dart_fss\n",
    "import OpenDartReader\n",
    "\n",
    "API_key = '0d67945133e224c451452e071e0d8349969353e1' \n",
    "dart = OpenDartReader(API_key)\n",
    "dart_fss.set_api_key(API_key)\n",
    "\n",
    "bsns_year = '2024'\n",
    "reprt_code = '11011'\n",
    "reference_date = datetime(2025, 8, 12) # used for tenure calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f819811",
   "metadata": {},
   "source": [
    "### **Data Extraction (data_extraction_ipynb)**\n",
    "\n",
    "Produces all the raw data files necessary for preprocessing. All 7 csv files are saved in the raw data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29cc3db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data directory exists at: ..\\..\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "BASE_DATA_DIR = os.path.join(r'..\\..', 'data', 'raw')\n",
    "os.makedirs(BASE_DATA_DIR, exist_ok=True)\n",
    "print(f\"Raw data directory exists at: {BASE_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5cbc9",
   "metadata": {},
   "source": [
    "#### 0. save_df_to_csv\n",
    "</b>\n",
    "\n",
    "a helper function, called at the end of each function to save outputs as csv files within raw data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4945b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_csv(df: pd.DataFrame, file_path: str, index: bool = False):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    try:\n",
    "        df.to_csv(file_path, index=index)\n",
    "        print(f\"DataFrame saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving DataFrame to CSV {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee79881",
   "metadata": {},
   "source": [
    "#### 1. get_corp_code\n",
    "</b>\n",
    "\n",
    "\n",
    "pulls the most up to date list of corp codes with a single API call to the OPENDART zip file. Corp codes are unique reference codes assigned by OPENDART, distinct from stock number and used as required keys to access and pull full company (2. get_kospi_company_info) and executive (3. get_executive_status_data) info. \n",
    "</b>\n",
    "\n",
    "[OPENDART | Guide for Developers to Corporation code](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE001&apiId=AE00004)\n",
    "</b>\n",
    "\n",
    "Required Key: \n",
    "</b>\n",
    "\n",
    "- crtfc_key (API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corp_code(api_key: str, output_dir: str = BASE_DATA_DIR) -> pd.DataFrame:\n",
    "    url_code = f'https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={api_key}'\n",
    "    response = requests.get(url_code) \n",
    "\n",
    "    # check that the target directory exists \n",
    "    os.makedirs('dart_data', exist_ok=True)\n",
    "\n",
    "    # unzip and extract CORPCODE.xml\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        z.extractall('dart_data')\n",
    "        xml_path = os.path.join('dart_data', 'CORPCODE.xml')\n",
    "\n",
    "    # parse XML\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # filter for listed companies (6-digit stock code only) and append to df\n",
    "    corp_list = []\n",
    "    for corp in root.findall('list'):\n",
    "        stock_code = corp.findtext('stock_code')\n",
    "        if stock_code and len(stock_code) == 6:\n",
    "            corp_list.append({\n",
    "                'corp_code': corp.findtext('corp_code'),\n",
    "                'corp_name': corp.findtext('corp_name'),\n",
    "                'corp_eng_name': corp.findtext('corp_eng_name'),\n",
    "                'stock_code': stock_code\n",
    "            })\n",
    "\n",
    "    #save in raw data folder \n",
    "    corp_codes_df = pd.DataFrame(corp_list)\n",
    "    output_filepath = os.path.join(output_dir, 'listed_corp_codes.csv')\n",
    "    save_df_to_csv(corp_codes_df, output_filepath)\n",
    "    return corp_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8057e06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to ..\\..\\data\\raw\\listed_corp_codes.csv\n"
     ]
    }
   ],
   "source": [
    "all_corp_codes_df = get_corp_code(API_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3fde21",
   "metadata": {},
   "source": [
    "#### 2. get_kospi_company_info\n",
    "</b>\n",
    "\n",
    "passes in the list of corp codes from get_corp_code, filters for kospi codes, and fetches all detailed company info. OPENDART requires an individual call for each *corp_code*, resulting in a total execution time of: ~ 9 minutes for 3,000+ calls.\n",
    "\n",
    "[OPENDART | Guide for Developers to Overview of corporate status](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE001&apiId=AE00002)\n",
    "\n",
    "Required Keys: \n",
    "- crtfc_key (API key) \n",
    "- corp_code \n",
    "\n",
    "Kept Data: \n",
    "</b>\n",
    "\n",
    "\n",
    "| Key  | Name | \n",
    "| -------|-----|\n",
    "| corp_name | Formal name\t  | \n",
    "| stock_code  | Stock item code\t  | \n",
    "| ceo_nm  | Representative name  |\n",
    "| induty_code*  |  Industry code   | \n",
    "\n",
    "*induty_code: not relevant now, could be used later to compare industry norms\n",
    "\n",
    "Dropped Data (corp code and name are sufficient for identification):\n",
    "| Key  | Name |\n",
    "| -------|-----|\n",
    "| corp_name_eng  | English name\t  | \n",
    "| stock_name | Item name \t  | \n",
    "| corp_cls  |  Corporation type   | \n",
    "| jurir_no  |  Corporate registration No.   |\n",
    "| bizr_no | Business registration No.  | \n",
    "| adres | Address  | \n",
    "| hm_url  | Website URL  | \n",
    "| ir_url  | IR website  | \n",
    "| phn_no |  Telephone No.   | \n",
    "| fax_no  | Fax No.  | \n",
    "| est_dt  | Establishment date (YYYYMMDD)  | \n",
    "| acc_mt  | Month of settlement (MM)  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kospi_company_info(api_key: str, corp_codes_df: pd.DataFrame, output_dir: str = BASE_DATA_DIR) -> pd.DataFrame:\n",
    "    data = []\n",
    "    api_endpoint = \"https://engopendart.fss.or.kr/engapi/company.json\"\n",
    "\n",
    "    for i, row in corp_codes_df.iterrows(): # iterate over list of corp_codes\n",
    "        corp_code = row['corp_code']\n",
    "        corp_name = row['corp_name']\n",
    "\n",
    "        params = { # OPENDART required keys\n",
    "            'crtfc_key': API_key,\n",
    "            'corp_code': corp_code\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(api_endpoint, params=params)\n",
    "            response.raise_for_status() # raise HTTPError for bad responses \n",
    "            info = response.json()\n",
    "\n",
    "            # filter for KOSPI companies \n",
    "            if info and info.get('corp_cls') == 'Y': # all types: Y (KOSPI), K (KOSDAQ), N (KONEX), E (Other)\n",
    "                data.append({\n",
    "                    'corp_name': info.get('corp_name'),\n",
    "                    'corp_code': info.get('corp_code'),\n",
    "                    'stock_code': info.get('stock_code'),\n",
    "                    'ceo_name': info.get('ceo_nm'),\n",
    "                    'industry_code': info.get('induty_code'),\n",
    "                })\n",
    "            time.sleep(0.07) # respect API limit\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch company info for {corp_name} ({corp_code}): {e}\")\n",
    "            continue\n",
    "    \n",
    "    # save in raw data folder\n",
    "    kospi_codes_df = pd.DataFrame(data)\n",
    "    output_filepath = os.path.join(output_dir, 'kospi_company_info.csv')\n",
    "    save_df_to_csv(kospi_codes_df, output_filepath)\n",
    "    return kospi_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e67499e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to ..\\..\\data\\raw\\kospi_company_info.csv\n"
     ]
    }
   ],
   "source": [
    "kospi_company_info_df = get_kospi_company_info(api_key=API_key, corp_codes_df=all_corp_codes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44028172",
   "metadata": {},
   "source": [
    "#### 3. get_executive_status_data\n",
    "\n",
    "retrieves executive-level data by passing in the list of KOSPI listed corps. OPENDART requires an individual API call per corporation, with 850 calls ~ 2 minutes.\n",
    "As the function iterates over the KOSPI corps, it will flag any that have no executive data available.\n",
    "\n",
    "[OPENDART | Guide for Developers to Status of executives](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00011)\n",
    "\n",
    "Required Keys:\n",
    "- crtfc_key (API key)\n",
    "- corp_code \n",
    "- bsns_year (fiscal year)\n",
    "- reprt_code\n",
    "    - First Quarterly Report : 11013\n",
    "    - Semi-annual Report : 11012\n",
    "    - Third Quarterly Report : 11014\n",
    "    - Annual Report : 11011\n",
    "\n",
    "The resulting **executive_status_data_df** saves all the information available. In preprocessing, **exec_df** filters down based on the following: \n",
    "\n",
    "Kept Data: \n",
    "| Key  | Name | \n",
    "| -------|-----|\n",
    "| rcept_no | Filing No.  | \n",
    "| corp_cls | Corporation type\t  |\n",
    "| corp_code | Corporation code\t  | \n",
    "| corp_name | Corporation name\t  | \n",
    "| nm | Name  |\n",
    "| sexdstn | Gender  | \n",
    "| ofcps | Position  | \n",
    "| rgist_exctv_at | Registered officer status  | \n",
    "| fte_at | Full-time  | \n",
    "| chrg_job | Responsibilites  | \n",
    "| main_career | Professional Background  |\n",
    "| mxmm_shrholdr_relate | Relationship to Largest Shareholder  | \n",
    "| hffc_pd | Period of employment  | \n",
    "\n",
    "Dropped Data: \n",
    "| Key  | Name | \n",
    "| -------|-----|\n",
    "| birth_ym | Date of birth  | \n",
    "| tenure_end_on | Term expiration date  | \n",
    "| stlm_dt | Settlement date  | \n",
    "\n",
    "As tenure in company is sufficient for guaging expertise and *stlm_dt* is irrelevant given filter for year and report type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88a31a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_executive_status_data(api_key: str, kospi_codes_df: pd.DataFrame, bsns_year: int, reprt_code: str, output_dir: str = os.path.join('data', 'raw')) -> pd.DataFrame:\n",
    "    results = []\n",
    "    api_endpoint = \"https://opendart.fss.or.kr/api/exctvSttus.json\"\n",
    "\n",
    "    for idx, row in kospi_codes_df.iterrows():\n",
    "        corp_code = row['corp_code']\n",
    "        corp_name = row['corp_name']\n",
    "        stock_code = row['stock_code']\n",
    "\n",
    "        params = { #OPENDART required keys\n",
    "            'crtfc_key': api_key,\n",
    "            'corp_code': corp_code,\n",
    "            'bsns_year': bsns_year,\n",
    "            'reprt_code': reprt_code\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(api_endpoint, params=params)\n",
    "            response.raise_for_status() # raise error for bad responses \n",
    "            data = response.json()\n",
    "\n",
    "            if data['status'] == '000': # success - data found\n",
    "                if 'list' in data and data['list']:\n",
    "                    df = pd.DataFrame(data['list']) # appends all info, later filtered down in preprocessing\n",
    "                    df['stock_code'] = stock_code\n",
    "                    \n",
    "                    results.append(df)\n",
    "            else:\n",
    "                print(f\"No executive data available for {corp_name} ({corp_code}) for {bsns_year}/{reprt_code}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred for {corp_name} ({corp_code}): {e}\")\n",
    "\n",
    "        time.sleep(0.07) \n",
    "\n",
    "    if results:\n",
    "        executive_status_df = pd.concat(results, ignore_index=True)\n",
    "        output_filepath = os.path.join(output_dir, f'executive_status_{bsns_year}_{reprt_code}.csv')\n",
    "        save_df_to_csv(executive_status_df, output_filepath)\n",
    "        return executive_status_df\n",
    "    else:\n",
    "        print(\"\\nNo executive status data was retrieved.\")\n",
    "        return pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "646dd740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No executive data available for 미래에셋맵스 아시아퍼시픽 부동산공모 1호 투자회사 (00600013) for 2024/11011.\n",
      "No executive data available for 맥쿼리한국인프라투융자회사 (00435297) for 2024/11011.\n",
      "No executive data available for 한국투자ANKOR유전해외자원개발특별자산투자회사1호(지분증권) (00907013) for 2024/11011.\n",
      "No executive data available for 케이비발해인프라투융자회사 (01880801) for 2024/11011.\n",
      "No executive data available for 주식회사 대신밸류리츠위탁관리부동산투자회사 (01885222) for 2024/11011.\n",
      "No executive data available for 대한조선 주식회사 (00182696) for 2024/11011.\n",
      "DataFrame saved to data\\raw\\executive_status_2024_11011.csv\n"
     ]
    }
   ],
   "source": [
    "executive_status_data_df = get_executive_status_data(API_key, kospi_company_info_df, bsns_year, reprt_code) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adbaf87",
   "metadata": {},
   "source": [
    "#### 4. get_total_assets  \n",
    "\n",
    "makes calls to OPENDART's financial statements API to pull total assets from each corp. For each corp, if a consolidated report ('CFS') exists, it will pull information from that statement. Otherwise, it will fall back on the seperate report ('OFS'). The function supports pulling other FS data, so long as sj_div and sj_nm are located correctly, and *target_account_names* is updated to reflect the target key words. The full function makes 850 (length of KOSPI codes) calls, with execution time ~ 3 minutes.\n",
    "\n",
    "\n",
    "[OPENDART | Single company’s full financial statements 개발가이드](https://opendart.fss.or.kr/guide/detail.do?apiGrpCd=DE003&apiId=AE00036)\n",
    "\n",
    "Required Keys:\n",
    "- crtfc_key (API key)\n",
    "- corp_code \n",
    "- bsns_year (fiscal year)\n",
    "- reprt_code \n",
    "- fs_div (seperate/consolidated report)\n",
    "\n",
    "The resulting **assets_YYYY_REPORT**  will be used to check requirements for mandated audit committees (corporations with total assets > $2T KRW). Because corporations have a two year grace period for forming a mandated audit committee, the function pulls total assets from the past three years. \n",
    "\n",
    "To see the full list of datapoints that can be extracted (ie Revenue, Profit, Liabilities):\n",
    "\n",
    "Kept Data: \n",
    "| Key  | Name | \n",
    "| -------|-----|\n",
    "| rcept_no* | Filing No.  | \n",
    "| thstrm_amount\t| Term amount |\n",
    "| frmtrm_amount\t| Previous term amount | \n",
    "| bfefrmtrm_amount\t| Amount of term before previous | \n",
    "\n",
    "Dropped Data: \n",
    "| Key  | Name | \n",
    "| -------|-----|\n",
    "| reprt_code | Report code\t  | \n",
    "| bsns_year | Fiscal year\t  | \n",
    "| corp_code | Corporation code\t  | \n",
    "| sj_div** | Type of financial statement\t  |\n",
    "| sj_nm | Financial statement title\t  |\n",
    "| account_id | Account ID  |\n",
    "| account_nm | Account name  | \n",
    "| account_detail | Detail account  |\n",
    "| thstrm_nm\t| Term name  | \n",
    "| thstrm_add_amount\t | Accumulated term amount\t  | \n",
    "| frmtrm_nm\t| Previous term name | \n",
    "| frmtrm_q_nm | Previous term name(Quarterly/Semiannual) | \n",
    "| frmtrm_q_amount | Previous term amount(Quarterly/Semiannual) | \n",
    "| frmtrm_add_amount\t| Accumulated previous term amount  | \n",
    "| bfefrmtrm_nm\t| Name of term before previous | \n",
    "| ord\t| Account code sort order | \n",
    "| currency\t| Currency unit |\n",
    "\n",
    "*required key for subdoc searches in preprocessing\n",
    "\n",
    "**function already filters for sj_div = BS, can change to retrieve data from other statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca9c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_assets(kospi_company_info_df: pd.DataFrame, bsns_year: str, reprt_code: str, API_key: str, output_dir: str = os.path.join('data', 'raw')) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches Total Assets for a list of companies from the DART API without helper functions.\n",
    "    \"\"\"\n",
    "    api_url = 'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json'\n",
    "    target_sj_div = \"BS\"\n",
    "    target_account_names = {\"자산총계\", \"총자산\", \"자산\"} # checks for possible categories covering total assets \n",
    "    year = int(bsns_year)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for corp_code in kospi_company_info_df['corp_code']:\n",
    "        rcept_no, assets, prior_assets, two_years_ago = None, None, None, None\n",
    "        \n",
    "        # try CFS first, fall back on OFS\n",
    "        for fs_div in ['CFS', 'OFS']:\n",
    "            params = {'crtfc_key': API_key, 'corp_code': corp_code, 'bsns_year': bsns_year, 'reprt_code': reprt_code, 'fs_div': fs_div}\n",
    "            try:\n",
    "                res = requests.get(api_url, params=params)\n",
    "                res.raise_for_status()\n",
    "                data = res.json()\n",
    "                \n",
    "                if data.get('status') == '000' and 'list' in data:\n",
    "                    # search for assets data directly from the JSON list\n",
    "                    for item in data['list']:\n",
    "                        if item['sj_div'] == target_sj_div and item['account_nm'].strip().replace(' ', '') in target_account_names:\n",
    "                            rcept_no = item.get('rcept_no')\n",
    "                            assets = pd.to_numeric(item.get('thstrm_amount', '').replace(',', ''), errors='coerce')\n",
    "                            prior_assets = pd.to_numeric(item.get('frmtrm_amount', '').replace(',', ''), errors='coerce')\n",
    "                            two_years_ago = pd.to_numeric(item.get('bfefrmtrm_amount', '').replace(',', ''), errors='coerce')\n",
    "                            break \n",
    "                    \n",
    "                    if assets is not None:\n",
    "                        break \n",
    "            \n",
    "            except (requests.exceptions.RequestException, ValueError):\n",
    "                continue\n",
    "        \n",
    "        if assets is None:\n",
    "            print(f\"Total Assets not found for {corp_code}.\")\n",
    "\n",
    "        all_results.append({\n",
    "            'corp_code': corp_code,\n",
    "            'rcept_no': rcept_no,\n",
    "            f'{year}_total_assets': assets,\n",
    "            f'{year - 1}_total_assets': prior_assets,\n",
    "            f'{year - 2}_total_assets': two_years_ago\n",
    "        })\n",
    "        \n",
    "        time.sleep(0.07)\n",
    "\n",
    "    assets_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    for y_offset in [0, 1, 2]:\n",
    "        col_name = f'{year - y_offset}_total_assets'\n",
    "        if col_name in assets_df.columns:\n",
    "            assets_df[col_name] = pd.to_numeric(assets_df[col_name], errors='coerce').astype('Int64')\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"assets_{bsns_year}_{reprt_code}.csv\")\n",
    "    assets_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    return assets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0e2dca7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Assets not found for 00600013.\n",
      "Total Assets not found for 00435297.\n",
      "Total Assets not found for 00907013.\n",
      "Total Assets not found for 01880801.\n",
      "Total Assets not found for 00112998.\n",
      "Total Assets not found for 01885222.\n",
      "Total Assets not found for 00182696.\n"
     ]
    }
   ],
   "source": [
    "assets_df = get_total_assets(kospi_company_info_df, bsns_year, reprt_code, API_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036bd84d",
   "metadata": {},
   "source": [
    "#### 5. get_salary_type\n",
    "\n",
    "pulls salary data from three OPDENDART source types: \n",
    "- Individual, which discloses the exact amount for executives making more than 500M KRW. \n",
    "- Grouped, which provides total annual grouped salary and average salaries by status type. \n",
    "- Unregistered, which provides the total annual grouped salary and average per person.\n",
    "\n",
    "In the preprocessing notebook, salary will be appended to each executive - exact where possible and average amounts otherwise. Because there are three separate API endpoints, **get_salary_type** contains two internal helped functions: **_get_json** and **_get_salary_data_for_corp**. When the main function is called, the list of KOSPI *corp_codes* is passed as keys to **_get_salary_data_for_corp**, which makes separate calls to each source type using **_get_json**. All the disclosed datapoints are then appended larger, consolidated dataframe saved as **salary_data_YYYY_REPORT** in the raw data folder, and refered to within this notebook as **salary_separate_df**. If any errors occur in retrieving a corp's data, the details will be flagged and printed. Each corp code makes 3 API requests, totaling 2550 executing in ~ 4 minutes.\n",
    "\n",
    "1. [OPENDART | Guide for Developers to Remuneration for individual directors and auditors](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00013) (lists all those > 500m KRW)\n",
    "\n",
    "2. [OPENDART | Guide for Developers to Remuneration for all directors and auditors (remuneration paid - by type)](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00030)\n",
    "\n",
    "3. [OPENDART | Guide for Developers to Remuneration for unregistered executives](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00028)\n",
    "\n",
    "Required Keys:\n",
    "- crtfc_key (API key)\n",
    "- corp_code \n",
    "- bsns_year (fiscal year)\n",
    "- reprt_code \n",
    "\n",
    "The resulting **salary_separate_df** displays the salary data pulled from the three datapoints, with standardized columns for the purposes of merging with **exec_df** in the preprocessing notebook. The following chart maps the resulting **salary_separate_df**'s column names to the corresponding OPENDART source.\n",
    "\n",
    "| salary_separate_df column  | (1.) Individual | (2.) All By Type | (3.) Unregistered | \n",
    "| -------|-----|-----|-----|\n",
    "| position | ofcps | se (category)* | se\t(unregistered) |\n",
    "| compensation | mendng_totamt | psn1_avrg_pymntamt | jan_salary_am |\n",
    "| salary_source | 개인별보수 | 임원전체보수유형 | 미등기임원 |\n",
    "| salary_type | exact | estimate | estimate | \n",
    "\n",
    "\n",
    "*Category covers:\n",
    "\n",
    "- Registered director (excluding outside directors and members of the audit committee)\n",
    "- Outside director (excluding members of the audit committee)\n",
    "- Member of the audit committee\n",
    "- Auditors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e8c5ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary_type(kospi_company_info_df: pd.DataFrame, bsns_year: str, reprt_code: str, API_key: str, output_dir: str = os.path.join('data', 'raw')) -> pd.DataFrame:\n",
    "    # === Internal Helper Function: DART API JSON request ===\n",
    "    def _get_json(url, corp_code):\n",
    "        \"\"\"Helper to fetch JSON data from DART API and handle errors.\"\"\"\n",
    "        params = {\n",
    "            'crtfc_key': API_key,\n",
    "            'corp_code': corp_code,\n",
    "            'bsns_year': bsns_year,\n",
    "            'reprt_code': reprt_code\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get('status') != '000' or 'list' not in data:\n",
    "                if data.get('status') != '000':\n",
    "                    print(f\"OPENDART Error for {corp_code}: {data.get('message')}\")\n",
    "                return []\n",
    "            return data['list']\n",
    "        except Exception as e:\n",
    "            print(f\"Request failed for {url} with params {params}: {e}\")\n",
    "            return []\n",
    "\n",
    "    # === Internal Helper Function: Fetches data for a single company ===\n",
    "    def _get_salary_data_for_corp(corp_code):\n",
    "        \"\"\"Fetches and consolidates salary data for a single company.\"\"\"\n",
    "        endpoints = {\n",
    "            'individual': 'https://opendart.fss.or.kr/api/hmvAuditIndvdlBySttus.json',\n",
    "            'unregistered': 'https://opendart.fss.or.kr/api/unrstExctvMendngSttus.json',\n",
    "            'grouped': 'https://opendart.fss.or.kr/api/drctrAdtAllMendngSttusMendngPymntamtTyCl.json' \n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        # 1. Individual executives (개인별 보수)\n",
    "        for row in _get_json(endpoints['individual'], corp_code):\n",
    "            results.append({\n",
    "                'corp_code': corp_code,\n",
    "                'name': row.get('nm'),\n",
    "                'position': row.get('ofcps'),\n",
    "                'compensation': row.get('mendng_totamt'), \n",
    "                'salary_source': '개인별보수',\n",
    "                'salary_type': 'exact'\n",
    "            })\n",
    "\n",
    "        # 2. Unregistered executives (미등기 임원)\n",
    "        for row in _get_json(endpoints['unregistered'], corp_code):\n",
    "            results.append({\n",
    "                'corp_code': corp_code,\n",
    "                'name': '',\n",
    "                'position': row.get('se'),\n",
    "                'compensation': row.get('jan_salary_am'), \n",
    "                'salary_source': '미등기임원',\n",
    "                'salary_type': 'estimate'\n",
    "            })\n",
    "\n",
    "        # 3. Grouped executives (임원 전체 보수 유형)\n",
    "        for row in _get_json(endpoints['grouped'], corp_code):\n",
    "            results.append({\n",
    "                'corp_code': corp_code,\n",
    "                'name': '',\n",
    "                'position': row.get('se'),\n",
    "                'compensation': row.get('psn1_avrg_pymntamt'),\n",
    "                'salary_source': '임원전체보수유형',\n",
    "                'salary_type': 'estimate'\n",
    "            })\n",
    "            \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    # === Main loop to process all companies ===\n",
    "    all_salary_data = []\n",
    "\n",
    "    for corp_code in kospi_company_info_df['corp_code'].apply(lambda c: str(c).zfill(8)):\n",
    "        df = _get_salary_data_for_corp(corp_code)\n",
    "        \n",
    "        if not df.empty:\n",
    "            all_salary_data.append(df)\n",
    "        \n",
    "        # Respect DART API rate limits\n",
    "        time.sleep(0.07)\n",
    "\n",
    "    # Concatenate all individual DataFrames into one\n",
    "    final_df = pd.concat(all_salary_data, ignore_index=True)\n",
    "    \n",
    "    # Save the final DataFrame to a CSV file\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"salary_separate_{bsns_year}_{reprt_code}.csv\")\n",
    "    final_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"Salary data for {len(all_salary_data)} companies saved to: {output_path}\")\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbd99ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENDART Error for 00600013: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00600013: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00600013: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00435297: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00435297: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00435297: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00907013: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00907013: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00907013: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 01880801: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 01880801: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 01880801: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 01885222: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 01885222: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 01885222: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00182696: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00182696: 조회된 데이타가 없습니다.\n",
      "OPENDART Error for 00182696: 조회된 데이타가 없습니다.\n",
      "Salary data for 844 companies saved to: data\\raw\\salary_separate_2024_11011.csv\n"
     ]
    }
   ],
   "source": [
    "salary_separate_df = get_salary_type(kospi_company_info_df, bsns_year, reprt_code, API_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945f624",
   "metadata": {},
   "source": [
    "#### 6. get_salary_total  \n",
    "\n",
    "pulls the total salary for each corp. \n",
    "\n",
    "[OPENDART | Guide for Developers to Remuneration for all directors and auditors](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00014)\n",
    "\n",
    "Required Keys:\n",
    "- crtfc_key (API key)\n",
    "- corp_code \n",
    "- bsns_year (fiscal year)\n",
    "- reprt_code \n",
    "\n",
    "The resulting **salary_total_df** keeps all response variables. This includes: \n",
    "- nmpr (total headcount of all directors and auditors)\n",
    "- mendng_totamt (total remuneration amount for all directors and auditors)\n",
    "- jan_avrg_mendng_am (the average remuneration per person)\n",
    "\n",
    "These points will be used to check **summary_df** values, to ensure that total headcount and remuneration totals align. The total remuneration amount is then merged with **summary_df** as a *Total Compensation* column. The functions makes ~850 calls and executes in ~ 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4020c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary_total(kospi_company_info_df: pd.DataFrame, bsns_year: str, reprt_code: str, API_key: str, output_dir: str = os.path.join('data', 'raw')) -> pd.DataFrame:\n",
    "    url = \"https://opendart.fss.or.kr/api/hmvAuditAllSttus.json\"\n",
    "\n",
    "    # === Internal Helper Function: DART API JSON request ===\n",
    "    def _get_json(url, corp_code):\n",
    "        params = {\n",
    "            'crtfc_key': API_key,\n",
    "            'corp_code': corp_code,\n",
    "            'bsns_year': bsns_year,\n",
    "            'reprt_code': reprt_code\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get('status') != '000' or 'list' not in data:\n",
    "                if data.get('status') != '000':\n",
    "                    print(f\"DART API Error for {corp_code}: {data.get('message')}\")\n",
    "                return []\n",
    "            return data['list']\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Request failed for {url} with params {params}: {e}\")\n",
    "            return []\n",
    "        \n",
    "    salary_total = []\n",
    "    \n",
    "    for corp_code in kospi_company_info_df['corp_code'].apply(lambda c: str(c).zfill(8)):\n",
    "        data_list = _get_json(url, corp_code)\n",
    "\n",
    "        if data_list:\n",
    "            df = pd.DataFrame(data_list)\n",
    "            salary_total.append(df)\n",
    "        \n",
    "        time.sleep(0.07)\n",
    "        \n",
    "    # concatenate all individual DataFrames into one\n",
    "    final_df = pd.concat(salary_total, ignore_index=True)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"salary_total_data_{bsns_year}_{reprt_code}.csv\")\n",
    "    final_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"Salary data for {len(salary_total)} companies saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f76336d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DART API Error for 00600013: 조회된 데이타가 없습니다.\n",
      "DART API Error for 00435297: 조회된 데이타가 없습니다.\n",
      "DART API Error for 00907013: 조회된 데이타가 없습니다.\n",
      "DART API Error for 01880801: 조회된 데이타가 없습니다.\n",
      "DART API Error for 01885222: 조회된 데이타가 없습니다.\n",
      "DART API Error for 00182696: 조회된 데이타가 없습니다.\n",
      "Salary data for 844 companies saved to: data\\raw\\salary_total_data_2024_11011.csv\n"
     ]
    }
   ],
   "source": [
    "salary_total_df = get_salary_total(kospi_company_info_df, bsns_year, reprt_code, API_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f09ca0",
   "metadata": {},
   "source": [
    "#### 7. get_major_shareholder_data\n",
    "\n",
    "pulls holding status of major shareholders. \n",
    "\n",
    "In the preprocessing notebook, shareholder status will be merged with the exec data, such that if a registered or unregistered executive is listed as a major shareholder, their shares will be appended to exec_df.\n",
    "\n",
    "[OPENDART | Guide for Developers to Information on largest shareholder](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE002&apiId=AE00008)\n",
    "\n",
    "Required Keys:\n",
    "- crtfc_key (API key)\n",
    "- corp_code \n",
    "- bsns_year (fiscal year)\n",
    "- reprt_code \n",
    "\n",
    "The resulting **major_shareholder_df** contains all response keys for potential further evaluation. When merged to **exec_df**, only *trmend_posesn_stock_qota_rt* (shareholding ratio at the end of the reporting period) is added as a *Shareholding Ratio* column. The following are not carried over: \n",
    "- bsis_posesn_stock_co\t(number of stocks at the beginning of the reporting period)\n",
    "- bsis_posesn_stock_qota_rt (shareholding ratio at the beginning of the reporting period)\n",
    "- trmend_posesn_stock_co (number of stocks at the end of the reporting period)\n",
    "\n",
    "Alternative Source: [OPENDART | Guide for Developers to Report of executives and major shareholders' ownership](https://engopendart.fss.or.kr/guide/detail.do?apiGrpCd=DE004&apiId=AE00041) which pulls stock transaction updates by executives and major shareholders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "271242e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_major_shareholder_data(api_key: str, kospi_codes_df: pd.DataFrame, bsns_year: int, reprt_code: str, output_dir: str = os.path.join('data', 'raw')) -> pd.DataFrame:\n",
    "    results = []\n",
    "    api_endpoint = \"https://opendart.fss.or.kr/api/hyslrSttus.json\"\n",
    "    total_corps = len(kospi_codes_df)\n",
    "\n",
    "    for idx, row in kospi_codes_df.iterrows():\n",
    "        corp_code = row['corp_code']\n",
    "        corp = str(corp_code).zfill(8)\n",
    "        corp_name = row['corp_name']\n",
    "\n",
    "        params = {\n",
    "            'crtfc_key': api_key,\n",
    "            'corp_code': corp,\n",
    "            'bsns_year': bsns_year,\n",
    "            'reprt_code': reprt_code\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(api_endpoint, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            if data['status'] == '000':\n",
    "                if 'list' in data and data['list']:\n",
    "                    df = pd.DataFrame(data['list'])\n",
    "                    results.append(df)\n",
    "            elif data['status'] == '013':\n",
    "                print(f\"No shareholder data available for {corp_name} ({corp_code}) for {bsns_year}/{reprt_code}.\")\n",
    "            else:\n",
    "                print(f\"API Error for {corp_name} ({corp_code}): Status {data.get('status')}, Message: {data.get('message')}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred for {corp_name} ({corp_code}): {e}\")\n",
    "\n",
    "        time.sleep(0.07)\n",
    "\n",
    "    if results:\n",
    "        shareholder_df = pd.concat(results, ignore_index=True)\n",
    "        output_filepath = os.path.join(output_dir, f'major_shareholders_{bsns_year}_{reprt_code}.csv')\n",
    "        save_df_to_csv(shareholder_df, output_filepath)\n",
    "        print(f\"\\nSuccessfully fetched and saved major shareholder data for {len(shareholder_df)} records.\")\n",
    "        return shareholder_df\n",
    "    else:\n",
    "        print(\"\\nNo major shareholder data was retrieved.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ce067eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No shareholder data available for 미래에셋맵스 아시아퍼시픽 부동산공모 1호 투자회사 (00600013) for 2024/11011.\n",
      "No shareholder data available for 맥쿼리한국인프라투융자회사 (00435297) for 2024/11011.\n",
      "No shareholder data available for 한국투자ANKOR유전해외자원개발특별자산투자회사1호(지분증권) (00907013) for 2024/11011.\n",
      "No shareholder data available for 케이비발해인프라투융자회사 (01880801) for 2024/11011.\n",
      "No shareholder data available for 주식회사 대신밸류리츠위탁관리부동산투자회사 (01885222) for 2024/11011.\n",
      "No shareholder data available for 대한조선 주식회사 (00182696) for 2024/11011.\n",
      "DataFrame saved to data\\raw\\major_shareholders_2024_11011.csv\n",
      "\n",
      "Successfully fetched and saved major shareholder data for 9102 records.\n"
     ]
    }
   ],
   "source": [
    "major_shareholder_df = get_major_shareholder_data(API_key, kospi_company_info_df, bsns_year, reprt_code) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f16c5",
   "metadata": {},
   "source": [
    "### **Data Extraction (data_extraction_ipynb)**\n",
    "\n",
    "Groups and concatonates data into two data dataframes: **exec_df** and **summary _df**. Unlike *data_extraction*, only the final cleaned and completed dfs will be saved to the processed data folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0fea6",
   "metadata": {},
   "source": [
    "#### 0. Build initial exec_df structure\n",
    "\n",
    "From the raw data file **executive_status_data_df**, the following cell drops the columns identified in *data extraction* (3.) get_executive_data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f674c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_df = executive_status_data_df.drop(\n",
    "    columns=['corp_cls', 'birth_ym', 'fte_at', 'tenure_end_on', 'stlm_dt'], \n",
    "    errors='ignore'\n",
    ").rename(\n",
    "    columns={\n",
    "        'rcept_no': 'disclosure',\n",
    "        'nm': 'name',\n",
    "        'sexdstn': 'gender',\n",
    "        'ofcps': 'position',\n",
    "        'rgist_exctv_at': 'exec_status',\n",
    "        'chrg_job': 'responsibilities',\n",
    "        'mxmm_shrholdr_relate': 'largest_shareholder_relate',\n",
    "        'hffc_pd': 'employment_period',\n",
    "        'trmend_posesn_stock_qota_rt': 'shareholding_ratio'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd801cc",
   "metadata": {},
   "source": [
    "#### **exec_df**\n",
    "#### 1. Parse Experience and Build Initial Structure\n",
    "\n",
    "separate_career passes in the prior_work column in **exec_df** to parse and categorize into education and work experience. The function prioritizes sorting work related roles first, to avoid education related positions. Job keywords only contains these related terms as the fallback defaults to work experience if the specific education keywords don't exist within each parsed string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "32165a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_career(career_string):\n",
    "    if pd.isna(career_string):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    education = []\n",
    "    work_experience = []\n",
    "    \n",
    "    # prioritized keywords\n",
    "    job_keywords = ['교수', '총장', '강사', '연구원', '학장', '팀장', '실장', '감사', '대표', '회장', '이사']\n",
    "    edu_keywords = ['학사', '석사', '박사', '대학교', '법학', '대학원', '졸업', '수료', 'Univ.', 'School', 'College', 'MBA', 'U.', 'Institute', 'University']\n",
    "\n",
    "    career_items = career_string.split('\\n')\n",
    "    \n",
    "    for item in career_items:\n",
    "        # check for job keywords for education-related backgrounds to avoid sorting as education \n",
    "        if any(keyword in item for keyword in job_keywords):\n",
    "            work_experience.append(item.strip())\n",
    "        # if no job keywords, check for educational keywords\n",
    "        elif any(keyword in item for keyword in edu_keywords):\n",
    "            education.append(item.strip())\n",
    "        # default to work experience for other entries\n",
    "        else:\n",
    "            work_experience.append(item.strip())\n",
    "            \n",
    "    return (\n",
    "        education if education else np.nan,\n",
    "        work_experience if work_experience else np.nan\n",
    "    )\n",
    "exec_df[['education', 'work_exp']] = exec_df['main_career'].apply(\n",
    "    lambda x: pd.Series(separate_career(x))\n",
    ")\n",
    "\n",
    "# drop the old career column and reorder the columns \n",
    "exec_df = exec_df.drop(columns=['main_career']).pipe(\n",
    "    lambda df: df[['stock_code'] + [col for col in df.columns if col != 'stock_code']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc21f1",
   "metadata": {},
   "source": [
    "#### 2. Individual Audit Committee Membership\n",
    "\n",
    "The following code block extracts audit committee membership and auditor status from individual **exec_df** rows, in order for proper counting in **summary_df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "71337c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_and_split(responsibility_string):\n",
    "    if not isinstance(responsibility_string, str):\n",
    "        return []\n",
    "    \n",
    "    # split the string by newlines, strip whitespace, and filter out empty strings\n",
    "    return [item.strip() for item in responsibility_string.split('\\n') if item.strip()]\n",
    "\n",
    "exec_df['responsibilities'] = exec_df['responsibilities'].apply(_clean_and_split)\n",
    "\n",
    "def is_audit_committee_member(responsibilities):\n",
    "    if not responsibilities:\n",
    "        return False\n",
    "    # check if any item in the list matches the audit committee pattern\n",
    "    for responsibility in responsibilities:\n",
    "        responsibility_cleaned = re.sub(r'\\s', '', responsibility)\n",
    "        if re.search(r'감사위원회위원|감사위원|감사위원장', responsibility_cleaned):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_auditor_exclusive(responsibilities):\n",
    "    if not responsibilities:\n",
    "        return False\n",
    "    # first, check if the person is an audit committee member and return False if they are\n",
    "    if is_audit_committee_member(responsibilities):\n",
    "        return False\n",
    "    \n",
    "    # otherwise, check for the isolated auditor pattern\n",
    "    for responsibility in responsibilities:\n",
    "        responsibility_cleaned = re.sub(r'\\s', '', responsibility)\n",
    "        if '감사' in responsibility_cleaned and not re.search(r'감사위원회위원|감사위원', responsibility_cleaned):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# apply the functions directly, performing the cleaning inside the lambda\n",
    "exec_df['is_audit_committee_member'] = exec_df['responsibilities'].apply(\n",
    "    lambda x: is_audit_committee_member(_clean_and_split(x))\n",
    ")\n",
    "\n",
    "exec_df['is_auditor'] = exec_df['responsibilities'].apply(\n",
    "    lambda x: is_auditor_exclusive(_clean_and_split(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990a58a6",
   "metadata": {},
   "source": [
    "#### 3. Assign Compensation\n",
    "\n",
    "assign_compensation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6c819288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_compensation(exec_df: pd.DataFrame, salary_type_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    exec_df['salary'] = None\n",
    "    exec_df['salary_source'] = None\n",
    "    exec_df['salary_type'] = None\n",
    "\n",
    "    for idx, row in exec_df.iterrows():\n",
    "        corp_code = row['corp_code']\n",
    "        name = row['name']\n",
    "        status = row.get('exec_status')\n",
    "        is_auditor = row.get('is_auditor', False)\n",
    "        is_committee = row.get('is_audit_committee_member', False)\n",
    "\n",
    "        # 1. Try to match by name\n",
    "        match = salary_separate_df[\n",
    "            (salary_separate_df['corp_code'] == corp_code) & \n",
    "            (salary_separate_df['name'] == name)\n",
    "        ]\n",
    "\n",
    "        if not match.empty:\n",
    "            row_data = match.iloc[0]\n",
    "\n",
    "        else:\n",
    "            if status == '미등기':\n",
    "                label = '미등기임원' \n",
    "            # 2. Estimate fallback: build label\n",
    "            elif is_auditor:\n",
    "                label = '감사'\n",
    "            elif status == '사외이사':\n",
    "                label = '감사위원회 위원' if is_committee else '사외이사(감사위원회 위원 제외)'\n",
    "            else:\n",
    "                label = '등기이사(사외이사, 감사위원회 위원 제외)'\n",
    "\n",
    "            group_match = salary_separate_df[\n",
    "                (salary_separate_df['corp_code'] == corp_code) & \n",
    "                (salary_separate_df['name'].isna()) & \n",
    "                (salary_separate_df['position'] == label)\n",
    "            ]\n",
    "\n",
    "            row_data = group_match.iloc[0] if not group_match.empty else pd.Series(dtype='object')\n",
    "\n",
    "        # 3. Assign if valid\n",
    "        if not row_data.empty:\n",
    "            exec_df.at[idx, 'salary'] = row_data.get('compensation')\n",
    "            exec_df.at[idx, 'salary_source'] = row_data.get('salary_source')\n",
    "            exec_df.at[idx, 'salary_type'] = row_data.get('salary_type')\n",
    "\n",
    "    return exec_df\n",
    "\n",
    "exec_df = assign_compensation(exec_df, salary_separate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c76624",
   "metadata": {},
   "source": [
    "#### 4. Merge Shareholder Data\n",
    "\n",
    "merges **exec_df** with **major_shareholder_df** to shareholding ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d8b60910",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_df = pd.merge(exec_df, major_shareholder_df[['corp_code', 'nm', 'trmend_posesn_stock_qota_rt']], \n",
    "                   left_on=['corp_code', 'name'], right_on=['corp_code', 'nm'], how='left')\n",
    "exec_df = exec_df.drop(columns=['nm']).rename(\n",
    "    columns={'trmend_posesn_stock_qota_rt': 'shareholding_ratio'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c2645",
   "metadata": {},
   "source": [
    "#### 5. Standardize Tenure\n",
    "\n",
    "merges **exec_df** with **major_shareholder_df** to shareholding ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2657458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tenure_to_months(tenure_str, current_date=None):\n",
    "    if pd.isna(tenure_str) or not isinstance(tenure_str, str) or not tenure_str.strip():\n",
    "        return pd.NA\n",
    "        \n",
    "    tenure_str = tenure_str.strip()\n",
    "    \n",
    "    # 1. all date formats, including those with extra text\n",
    "    date_match = re.search(r'(\\d{2,4}[년\\.\\s]\\d{1,2}[월]?(?:[년\\.\\s]\\d{1,2}[일])?|\\d{1,2}\\.\\d{1,2}\\.\\d{1,2})', tenure_str)\n",
    "    \n",
    "    if date_match:\n",
    "        date_str = date_match.group(1).replace(' ', '').replace('년', '.').replace('월', '').replace('일', '')\n",
    "        date_obj = pd.NaT\n",
    "        \n",
    "        # parse the cleaned date string with multiple formats\n",
    "        date_formats = ['%Y.%m.%d', '%Y.%m', '%d.%m.%y', '%y.%m.%d', '%y.%m']\n",
    "        for fmt in date_formats:\n",
    "            try:\n",
    "                date_obj = pd.to_datetime(date_str, format=fmt, errors='raise')\n",
    "                break # Exit the loop if parsing is successful\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "    \n",
    "        if pd.notna(date_obj):\n",
    "            if current_date is None:\n",
    "                current_date = datetime.now()\n",
    "            \n",
    "            total_months = (current_date.year - date_obj.year) * 12 + (current_date.month - date_obj.month)\n",
    "            return float(max(0, total_months))\n",
    "    \n",
    "    # 2. decimal years (e.g., '11.3년', '22.5')\n",
    "    match_deci = re.search(r'^(\\d+(?:\\.\\d+)?)(?:년)?$', tenure_str)\n",
    "    if match_deci:\n",
    "        decimal_years = float(match_deci.group(1))\n",
    "        return decimal_years * 12\n",
    "    \n",
    "    # 3. years and months (e.g., \"3년 6개월\", \"4년4개월\")\n",
    "    match_ym = re.search(r'(\\d+)\\s*년(?:[^\\d]+)?\\s*(\\d+)\\s*개월', tenure_str)\n",
    "    if match_ym:\n",
    "        years = int(match_ym.group(1))\n",
    "        months = int(match_ym.group(2))\n",
    "        return float(years * 12 + months)\n",
    "        \n",
    "    # 4. years only (e.g., \"3년\")\n",
    "    match_y = re.search(r'^(\\d+)\\s*년$', tenure_str)\n",
    "    if match_y:\n",
    "        years = int(match_y.group(1))\n",
    "        return float(years * 12)\n",
    "        \n",
    "    # 5. months only (e.g., \"18개월\")\n",
    "    match_m = re.search(r'^(\\d+)\\s*개월$', tenure_str)\n",
    "    if match_m:\n",
    "        months = int(match_m.group(1))\n",
    "        return float(months)\n",
    "    \n",
    "    return pd.NA\n",
    "\n",
    "exec_df['employment_period'] = exec_df['employment_period'].apply(\n",
    "    lambda x: convert_tenure_to_months(x, current_date=reference_date) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60faa94",
   "metadata": {},
   "source": [
    "#### **summary_df**\n",
    "\n",
    "#### 1. Build Initial summary_df\n",
    "\n",
    "groups and summarizes **exec_df** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ff5a50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_summary_optimized(group):\n",
    "    voting_directors_group = group[~group['exec_status'].isin(['미등기', '감사'])]\n",
    "    female_voting = (voting_directors_group['gender'] == '여').sum()\n",
    "    male_voting = (voting_directors_group['gender'] == '남').sum()\n",
    "\n",
    "    return pd.Series({\n",
    "        'audit_committee': group['is_audit_committee_member'].sum(),\n",
    "        'audit_committee_ods': ((group['is_audit_committee_member']) & (group['exec_status'] == '사외이사')).sum(),\n",
    "        'inside_directors': group['exec_status'].isin(['사내이사', '대표집행임원']).sum(),\n",
    "        'outside_directors': (group['exec_status'] == '사외이사').sum(),\n",
    "        'female_voting': female_voting,\n",
    "        'male_voting': male_voting,\n",
    "        'voting_directors': female_voting + male_voting,\n",
    "        'other_non_exec_directors': (group['exec_status'] == '기타비상무이사').sum(),\n",
    "        'auditors': group['is_auditor'].sum(),\n",
    "        'non_registered': (group['exec_status'] == '미등기').sum()\n",
    "    })\n",
    "\n",
    "summary_df = exec_df.groupby(['stock_code', 'corp_code', 'corp_name'], as_index=False).apply(\n",
    "    extract_summary_optimized, include_groups=False\n",
    ")\n",
    "\n",
    "summary_df = pd.merge(\n",
    "    summary_df,\n",
    "    assets_df[['corp_code', '2024_total_assets', '2023_total_assets', '2022_total_assets']],\n",
    "    on='corp_code',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "disclosure = exec_df.groupby('corp_code')['disclosure'].max().reset_index()\n",
    "summary_df = pd.merge(\n",
    "    summary_df,\n",
    "    disclosure,\n",
    "    on='corp_code',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752861ef",
   "metadata": {},
   "source": [
    "#### 2. Audit Committee Checks\n",
    "\n",
    "For **summary_df**, each corp will undergo two rounds of governance checks (*check_governance_compliance*). After the first pass, to make sure that the flagged corporations are due to actual discrepencies and not incomplete data that was originally reported and pulled from OPENDART's exec_df (where for example, an outside committee member is not listed as an executive but does hold an active position) will parse the corp's financial statement, correct missing data, and run through the check again. To access the audit committee details directly, **missing_acm_urls(flagged_df)** will pull the relevant url from opendart reader's subdocs function. The direct link to the audit committee file will then be parsed through in **parse_and_update_audit_members(audit_targets_df, exec_df, summary_df)** function. If the **summary_df** data on audit committee size and membership doesn't match what's listed on the financial document directly, the function will update **summary_df**. On the second pass, corps that fail the governance checks will be flagged, alongside their failed condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebfff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_governance_compliance(df):\n",
    "    flagged = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        corp_code = row['corp_code']\n",
    "        total_assets_target = row['2022_total_assets']\n",
    "        total_assets_fallback = row['2023_total_assets']\n",
    "        total_assets_fallback2 = row['2024_total_assets']\n",
    "        num_audit_committee = row['audit_committee']\n",
    "        num_outside_directors = row['outside_directors']\n",
    "        num_voting_directors = row['Voting Directors']\n",
    "        num_outside_committee = row['Audit Committee ODs']\n",
    "\n",
    "        failures = []\n",
    "\n",
    "        # Check audit committee compliances\n",
    "        if pd.notna(total_assets_target) and total_assets_target > 2_000_000_000_000:\n",
    "            if pd.isna(num_audit_committee) or num_audit_committee == 0:\n",
    "                failures.append(\"No Audit Committee listed\")\n",
    "            elif num_audit_committee < 3:\n",
    "                failures.append(f\"Audit Committee has fewer than 3 members ({num_audit_committee})\")\n",
    "\n",
    "            if pd.notna(num_audit_committee) and num_audit_committee > 0:\n",
    "                if pd.isna(num_outside_committee):\n",
    "                    failures.append(\"Missing count of Audit Committee Outside Directors.\")\n",
    "                elif num_outside_committee < (2/3) * num_audit_committee:\n",
    "                    failures.append(f\"Audit Committee Outside Directors ({num_outside_committee}) < 2/3 of Audit Committee ({num_audit_committee})\")\n",
    "            if num_outside_directors < (1/4) * num_voting_directors:\n",
    "                failures.append(f\"Outside Directors ({num_outside_directors}) < 1/4 of Voting Directors ({num_voting_directors})\")\n",
    "\n",
    "        if failures:\n",
    "            flagged.append({'corp_code': corp_code, 'Flagged Conditions': \"; \".join(failures)})\n",
    "\n",
    "    failed_df = pd.DataFrame(flagged)\n",
    "    failed_df['corp_code'] = failed_df['corp_code']\n",
    "\n",
    "    return pd.merge(failed_df, df, on='corp_code', how='inner')\n",
    "\n",
    "flagged = check_governance_compliance(summary_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd359c95",
   "metadata": {},
   "source": [
    "##### 2A. check_governance_compliance\n",
    "\n",
    "runs checks on **summary_df**. Checks for the following: \n",
    "\n",
    "1. Mandated Audit Committee: If a corporation's total assets > 2T KRW, an audit committee exists. As corporations have a 2 year grace period, the function passes in the total asset value from 2 years prior. If a corporation has no reported total assets for that year, it falls back back on the year after. \n",
    "2. Outside Majority: If a mandated audit committee exists, outside directors must make up a majority of the acting members. \n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a9545e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_governance_compliance(df):\n",
    "    \n",
    "    # 1. Prepare asset-based conditions\n",
    "    # Use the first available asset column.\n",
    "    df['total_assets'] = df['2022_total_assets'].fillna(df['2023_total_assets']).fillna(df['2024_total_assets'])\n",
    "    is_large_company = df['total_assets'] > 2_000_000_000_000\n",
    "\n",
    "    # 2. Define compliance failure conditions using vectorized operations\n",
    "    \n",
    "    # Rule 1: For all listed companies, outside directors must be at least 1/4 of voting directors.\n",
    "    # The check is for failure, so it's `<`.\n",
    "    outside_ratio_fail = df['outside_directors'] < (1/4) * df['voting_directors']\n",
    "\n",
    "    # Rule 2: For large companies, the audit committee must have at least 3 members.\n",
    "    # The check is for failure: having fewer than 3 members, or not having one at all.\n",
    "    audit_committee_fail = is_large_company & (\n",
    "        df['audit_committee'].isna() | (df['audit_committee'] < 3)\n",
    "    )\n",
    "\n",
    "    # Rule 3: For large companies with an audit committee, outside directors must be at least 2/3 of the committee.\n",
    "    # The check is for failure: the ratio is less than 2/3.\n",
    "    committee_majority_fail = is_large_company & (\n",
    "        df['audit_committee_ods'] < (2/3) * df['audit_committee']\n",
    "    )\n",
    "\n",
    "    # Rule 4: For large companies, outside directors must make up a majority (> 1/2) of total voting directors.\n",
    "    # This rule is stricter than Rule 1. The check is for failure: less than 1/2.\n",
    "    voting_majority_fail = is_large_company & (\n",
    "        df['outside_directors'] <= (1/2) * df['voting_directors']\n",
    "    )\n",
    "\n",
    "    # Rule 5: For large companies, there must be a minimum of 3 outside directors.\n",
    "    # The check is for failure: having fewer than 3.\n",
    "    outside_minimum_fail = is_large_company & (\n",
    "        df['outside_directors'] < 3\n",
    "    )\n",
    "\n",
    "    # 3. Create a list of all failure conditions and corresponding messages\n",
    "    failure_conditions = [\n",
    "        (outside_ratio_fail, \"Outside Directors < 1/4 of Voting Directors\"),\n",
    "        (audit_committee_fail, \"Audit Committee has fewer than 3 members or none listed\"),\n",
    "        (committee_majority_fail, \"Audit Committee Outside Directors < 2/3 of Audit Committee\"),\n",
    "        (voting_majority_fail, \"Outside Directors do not make up a majority of Voting Directors\"),\n",
    "        (outside_minimum_fail, \"Fewer than 3 Outside Directors\")\n",
    "    ]\n",
    "\n",
    "    # 4. Compile all failures into a single DataFrame and create the combined message\n",
    "    all_failures_mask = outside_ratio_fail | audit_committee_fail | committee_majority_fail | voting_majority_fail | outside_minimum_fail\n",
    "    df_with_failures = df.loc[all_failures_mask].copy()\n",
    "    \n",
    "    # Efficiently build the 'Flagged Conditions' string for each flagged company\n",
    "    def get_failure_messages(row):\n",
    "        messages = []\n",
    "        if row['outside_ratio_fail']:\n",
    "            messages.append(f\"Outside Directors ({row['outside_directors']}) < 1/4 of Voting Directors ({row['voting_directors']})\")\n",
    "        if row['audit_committee_fail']:\n",
    "            messages.append(f\"Audit Committee has fewer than 3 members ({row['audit_committee']})\")\n",
    "        if row['committee_majority_fail']:\n",
    "            messages.append(f\"Audit Committee Outside Directors ({row['audit_committee_ods']}) < 2/3 of Audit Committee ({row['audit_committee']})\")\n",
    "        if row['voting_majority_fail']:\n",
    "            messages.append(f\"Outside Directors ({row['outside_directors']}) do not make up a majority of Voting Directors ({row['voting_directors']})\")\n",
    "        if row['outside_minimum_fail']:\n",
    "            messages.append(f\"Fewer than 3 Outside Directors ({row['outside_directors']})\")\n",
    "        return \"; \".join(messages)\n",
    "\n",
    "    # Add failure columns to the temporary DataFrame for a clean application\n",
    "    df_with_failures['outside_ratio_fail'] = outside_ratio_fail\n",
    "    df_with_failures['audit_committee_fail'] = audit_committee_fail\n",
    "    df_with_failures['committee_majority_fail'] = committee_majority_fail\n",
    "    df_with_failures['voting_majority_fail'] = voting_majority_fail\n",
    "    df_with_failures['outside_minimum_fail'] = outside_minimum_fail\n",
    "\n",
    "    # Apply the function to each row\n",
    "    df_with_failures['Flagged Conditions'] = df_with_failures.apply(get_failure_messages, axis=1)\n",
    "\n",
    "    return df_with_failures.drop(columns=[\n",
    "        'total_assets', 'outside_ratio_fail', 'audit_committee_fail', 'committee_majority_fail',\n",
    "        'voting_majority_fail', 'outside_minimum_fail'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d0beb92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged = check_governance_compliance(summary_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cc5bf641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_code</th>\n",
       "      <th>corp_code</th>\n",
       "      <th>corp_name</th>\n",
       "      <th>audit_committee</th>\n",
       "      <th>audit_committee_ods</th>\n",
       "      <th>inside_directors</th>\n",
       "      <th>outside_directors</th>\n",
       "      <th>female_voting</th>\n",
       "      <th>male_voting</th>\n",
       "      <th>voting_directors</th>\n",
       "      <th>other_non_exec_directors</th>\n",
       "      <th>auditors</th>\n",
       "      <th>non_registered</th>\n",
       "      <th>2024_total_assets</th>\n",
       "      <th>2023_total_assets</th>\n",
       "      <th>2022_total_assets</th>\n",
       "      <th>disclosure</th>\n",
       "      <th>Flagged Conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000070</td>\n",
       "      <td>00126937</td>\n",
       "      <td>삼양홀딩스</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5290507469287</td>\n",
       "      <td>5154457321588</td>\n",
       "      <td>4547780622106</td>\n",
       "      <td>20250320000941</td>\n",
       "      <td>Audit Committee has fewer than 3 members (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000080</td>\n",
       "      <td>00150244</td>\n",
       "      <td>하이트진로</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>3441538598928</td>\n",
       "      <td>3358347205530</td>\n",
       "      <td>3333438311387</td>\n",
       "      <td>20250320000493</td>\n",
       "      <td>Audit Committee has fewer than 3 members (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000100</td>\n",
       "      <td>00145109</td>\n",
       "      <td>유한양행</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2942048836634</td>\n",
       "      <td>2812305590753</td>\n",
       "      <td>2472728072149</td>\n",
       "      <td>20250312001137</td>\n",
       "      <td>Audit Committee has fewer than 3 members (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000120</td>\n",
       "      <td>00113410</td>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9743855522383</td>\n",
       "      <td>9357587266747</td>\n",
       "      <td>9693299818264</td>\n",
       "      <td>20250317000953</td>\n",
       "      <td>Audit Committee has fewer than 3 members (0); ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000140</td>\n",
       "      <td>00148993</td>\n",
       "      <td>하이트진로홀딩스</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4077443964617</td>\n",
       "      <td>3979751148746</td>\n",
       "      <td>3945000964667</td>\n",
       "      <td>20250320000510</td>\n",
       "      <td>Audit Committee has fewer than 3 members (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>451800</td>\n",
       "      <td>01669226</td>\n",
       "      <td>한화리츠</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1586401656876</td>\n",
       "      <td>712472007685</td>\n",
       "      <td>710393030576</td>\n",
       "      <td>20250110000545</td>\n",
       "      <td>Outside Directors (0) &lt; 1/4 of Voting Director...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>460860</td>\n",
       "      <td>01765265</td>\n",
       "      <td>동국제강</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3194015021446</td>\n",
       "      <td>3531787086236</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20250317000722</td>\n",
       "      <td>Audit Committee has fewer than 3 members (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>481850</td>\n",
       "      <td>01714997</td>\n",
       "      <td>신한글로벌액티브리츠</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167620136884</td>\n",
       "      <td>168359472640</td>\n",
       "      <td>178103822513</td>\n",
       "      <td>20241118000337</td>\n",
       "      <td>Outside Directors (0) &lt; 1/4 of Voting Director...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>487570</td>\n",
       "      <td>01854763</td>\n",
       "      <td>HS효성</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1143492676338</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20250312000990</td>\n",
       "      <td>Outside Directors (0) &lt; 1/4 of Voting Director...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>499790</td>\n",
       "      <td>01882845</td>\n",
       "      <td>GS피앤엘</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2269555200465</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20250311001121</td>\n",
       "      <td>Audit Committee has fewer than 3 members (0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stock_code corp_code   corp_name  audit_committee  audit_committee_ods  \\\n",
       "3       000070  00126937       삼양홀딩스                0                    0   \n",
       "4       000080  00150244       하이트진로                0                    0   \n",
       "5       000100  00145109        유한양행                0                    0   \n",
       "6       000120  00113410      CJ대한통운                0                    0   \n",
       "7       000140  00148993    하이트진로홀딩스                0                    0   \n",
       "..         ...       ...         ...              ...                  ...   \n",
       "822     451800  01669226        한화리츠                0                    0   \n",
       "829     460860  01765265        동국제강                0                    0   \n",
       "836     481850  01714997  신한글로벌액티브리츠                0                    0   \n",
       "839     487570  01854763        HS효성                0                    0   \n",
       "841     499790  01882845       GS피앤엘                0                    0   \n",
       "\n",
       "     inside_directors  outside_directors  female_voting  male_voting  \\\n",
       "3                   3                  4              0            7   \n",
       "4                   2                  3              1            4   \n",
       "5                   2                  4              1            6   \n",
       "6                   3                  3              1            5   \n",
       "7                   2                  3              0            5   \n",
       "..                ...                ...            ...          ...   \n",
       "822                 8                  0              0            8   \n",
       "829                 2                  3              1            4   \n",
       "836                 1                  0              1            4   \n",
       "839                 3                  0              0            3   \n",
       "841                 1                  3              1            4   \n",
       "\n",
       "     voting_directors  other_non_exec_directors  auditors  non_registered  \\\n",
       "3                   7                         0         0              12   \n",
       "4                   5                         0         0              36   \n",
       "5                   7                         1         0              31   \n",
       "6                   6                         0         0               0   \n",
       "7                   5                         0         0               6   \n",
       "..                ...                       ...       ...             ...   \n",
       "822                 8                         0         0               0   \n",
       "829                 5                         0         0              20   \n",
       "836                 5                         4         0               0   \n",
       "839                 3                         0         0              12   \n",
       "841                 5                         1         0               0   \n",
       "\n",
       "     2024_total_assets  2023_total_assets  2022_total_assets      disclosure  \\\n",
       "3        5290507469287      5154457321588      4547780622106  20250320000941   \n",
       "4        3441538598928      3358347205530      3333438311387  20250320000493   \n",
       "5        2942048836634      2812305590753      2472728072149  20250312001137   \n",
       "6        9743855522383      9357587266747      9693299818264  20250317000953   \n",
       "7        4077443964617      3979751148746      3945000964667  20250320000510   \n",
       "..                 ...                ...                ...             ...   \n",
       "822      1586401656876       712472007685       710393030576  20250110000545   \n",
       "829      3194015021446      3531787086236               <NA>  20250317000722   \n",
       "836       167620136884       168359472640       178103822513  20241118000337   \n",
       "839      1143492676338               <NA>               <NA>  20250312000990   \n",
       "841      2269555200465               <NA>               <NA>  20250311001121   \n",
       "\n",
       "                                    Flagged Conditions  \n",
       "3         Audit Committee has fewer than 3 members (0)  \n",
       "4         Audit Committee has fewer than 3 members (0)  \n",
       "5         Audit Committee has fewer than 3 members (0)  \n",
       "6    Audit Committee has fewer than 3 members (0); ...  \n",
       "7         Audit Committee has fewer than 3 members (0)  \n",
       "..                                                 ...  \n",
       "822  Outside Directors (0) < 1/4 of Voting Director...  \n",
       "829       Audit Committee has fewer than 3 members (0)  \n",
       "836  Outside Directors (0) < 1/4 of Voting Director...  \n",
       "839  Outside Directors (0) < 1/4 of Voting Director...  \n",
       "841       Audit Committee has fewer than 3 members (0)  \n",
       "\n",
       "[276 rows x 18 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flagged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
